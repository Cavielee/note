# 事务使用场景

事务指当一个业务涉及一系列操作（对多个数据库表操作），我们对这一系列作为一个整体（事务）完成。该事务中的所有操作要么全部成功，要么全部失败。

例如银行转账，可以简单理解为一个账户转账为另一个账户，那么就一定有一方余额减少，一方余额增多这两个操作，这两个操作要么同时成功要么同时失败。



## 定义

事务是数据库管理系统（DBMS）执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成。
注意：

* 事务是数据库最小的工作单元，是不可以再分的。
* 事务可能包含了一个或者一系列的DML 语句，包括insert delete update。（单条DDL（create drop）和DCL（grant revoke）也会有事务）



# 存储引擎支持

MySQL 中 InnoDB 和 NDB（集群存储引擎） 是支持事务的，这也就是为什么 InnoDB 为默认存储引擎。



# 事务四大特性

事务的四大特性：ACID。



## 原子性（Atomicity）

原子性（Atomicity），事务被视为不可分割的最小单元，也就意味着我们对数据库的一系列的操作，要么全部提交成功，要么全部失败回滚。

原子性，在InnoDB 里面是通过undo log 来实现的，它记录了数据修改之前的值（逻辑日志），一旦发生异常，就可以用 undo log 来实现回滚操作。



## 一致性（Consistency）

一致性，consistent，指的是数据库的完整性约束没有被破坏，事务执行的前后都是合法的数据状态。比如主键必须是唯一的，字段长度符合要求。

除了数据库自身的完整性约束，还有一个是用户自定义的完整性。

用户自定义的完整性通常要在代码中控制。例如银行转账，A账户转账给B账户1000，A账户应该减1000，相对的B账户也要加上1000。



## 隔离性（Isolation）

多个事务中的操作可能同时对同一张表或者同一行数据进行操作，而隔离性是指避免这多个事务，对表或者行的并发操作，应该是透明的，互相不干扰的。从而保证业务数据的一致性。



## 持久性（Durable）

持久性（Durable）指事务对数据的任意操作，增删改，只要事务提交成功，那么结果就是永久性的，不可能因为我们系统宕机或者重启了数据库的服务器，它又恢复到原来的状态了。这个就是事务的持久性。

可以从前面存储结构可知，InnoDB 通过 redo log 和 double write 双写缓冲来实现的，我们操作数据的时候，会先写到内存的buffer pool 里面，同时记录redo log，如果在刷盘之前出现异常，在重启后就可以读取redo log 的内容，写入到磁盘，保证数据的持久性。

当然，恢复成功的前提是数据页本身没有被破坏，是完整的。如果数据页本身损坏，就会使用双写缓冲（double write）先将数据页恢复后在执行 redo log的恢复。



> 原子性，隔离性，持久性，最后都是为了实现一致性。



# 事务使用

无论是我们在Navicat 的这种工具里面去操作，还是在我们的Java 代码里面通过API 去操作，还是加上@Transactional 的注解或者AOP 配置，其实最终都是发送一个指令到数据库去执行，Java 的JDBC 只不过是把这些命令封装起来了。



## 事务开启和提交

### 自动开启和自动提交。

InnoDB 实际上会为sql语句自动开启一个事务，并在执行后自动提交事务。

通过 autocommit 参数控制事务自动开启和自动提交（默认值是ON）。

### 手动开启和提交

如果我们将 autocommit 参数修改成OFF（关闭），那么就需要我们手动去开启事务。可以通过 `begin;` 或者 `start transaction;` 两种方式开启事务。一般使用前者，因为简短。

对于手动开启的事务，需要我们去结束事务。可以通过以下方式：

1. `commit;` ，提交事务，事务执行的操作会全部提交成功。
2. `rollback`，回滚事务，事务执行过的操作会被回滚掉。
3. 如果是客户端连接，断开连接时，该客户端开启的事务也会结束。



> 当事务结束（提交或回滚），事务中持有的锁会被释放掉。



## 并发带来的问题

如果没有隔离性机制，那么事务并发执行时，可能会导致以下问题：

### 数据覆盖

事务T1和事务T2在事务结束前都对同一个数据进行修改，导致其中一个事务中的修改操作被其他事务的修改操作所覆盖。



### 脏读

事务T1读取了事务T2的修改后的数据，随后事务T2 Rollback，导致T1读取了不应该读取的数据。

脏读：读取到其他事务未提交的数据的情况。



### 不可重复读

事务T2读取一个数据，事务T1对该数据进行修改，如果T2再次读取该数据则结果与第一次读取的结果不同。

不可重复读：事务读取到了其他事务已提交的数据导致前后两次读取数据不一致。



### 幻读

事务T1读取数据，事务T2插入的新数据，T1再次读取时比第一次读取数据增多。

幻读：一个事务前后两次读取数据数量不一致（由于其他事务插入数据造成的）。



> 不可重复读是修改或者删除，幻读是插入。



无论是脏读，不可重复读，还是幻读，它们都是数据库的读一致性的问题，都是在一个事务里面前后两次读取出现了不一致的情况。



## 隔离机制

对于脏读、不可重复读、幻读这些事务并发导致读一致性的问题，数据库提供一定的事务隔离机制来解决。

数据库总结并提供了隔离机制的标准，并由各个厂商按照标准进行实现。对于隔离机制划分了4个等级，并且每个等级的隔离机制不同程度的解决读一致性问题：

* **Read Uncommitted（未提交读）:** 一个事务可以读取到其他事务未提交的数据，会出现脏读，所以叫做RU，它没有解决任何的问题。
* **Read Committed（已提交读）:** 一个事务只能读取到其他事务已提交的数据，不能读取到其他事务未提交的数据，它解决了脏读的问题，但是会出现不可重复读的问题。
* **Repeatable Read （可重复读）:** 它解决了不可重复读的问题，也就是在同一个事务里面多次读取同样的数据结果是一样的，但是在这个级别下，没有解决幻读的问题。
* **Serializable（串行化）:** 在这个隔离级别里面，所有的事务都是串行执行的，也就是对数据的操作需要排队，已经不存在事务的并发操作了，所以它解决了所有的问题。

> Oracle 里面就只有两种RC（已提交读）和Serializable（串行化）



# InnoDB 隔离级别实现

在MySQL InnoDB 里面，默认事务隔离级别为 Repeatable Read （可重复读），InnoDB 中该事务级别可以解决了幻读的问题（LBCC），因此不需要使用串行化的隔离级别去解决所有问题。



## 解决读一致性方案

### MVCC

多版本的并发控制MVCC（Multi Version Concurrency Control）。通过在事务开启前建立一个备份（快照），事务读取数据都会读取各自的快照，从而使得事务中每次读取，不会出现其他事务干扰，导致数据不一致性问题。

MVCC 的核心思想是： 可以查到在事务开始之前已经存在的数据，即使这些数据后面被其他事务修改或者删除。在事务开启后，其他事务新增的数据，我是查不到的。



#### 基于版本号实现

每个事务都会有一个事务ID，事务ID是自动递增的，把它理解为创建版本号。

InnoDB 为每行记录都实现了两个隐藏字段：

* **DB_TRX_ID：** 6 字节，插入或更新行的最后一个事务的事务ID，在数据新增或者修改为新数据的时候，记录该操作的事务ID。
* **DB_ROLL_PTR： **7 字节，回滚指针，可以把它理解为删除版本号，数据被删除或记录为旧数据的时候，记录该操作的事务ID。



MVCC 的查找规则：

* 能看到创建时间小于等于当前事务ID 的数据。
* 能看到删除时间大于当前事务ID 的行（或未删除）。



举例：

第一个事务创建，插入两条数据，并提交事务

此时事务id为1，隐藏的创建版本会改为1，删除版本为空。

| id   | name  | 创建版本 | 删除版本  |
| ---- | ----- | -------- | --------- |
| 1    | name1 | 1        | undefined |
| 2    | name2 | 1        | undefined |

第二个事务创建，并查询一次：

此时第二个事务id会变成2。

| id   | name  | 创建版本 | 删除版本  |
| ---- | ----- | -------- | --------- |
| 1    | name1 | 1        | undefined |
| 2    | name2 | 1        | undefined |

第三个事务创建，插入一条数据，并提交：

此时第三个事务id为3，新增的数据是由事务3操作，因此创建版本号为3。

| id   | name  | 创建版本 | 删除版本  |
| ---- | ----- | -------- | --------- |
| 1    | name1 | 1        | undefined |
| 2    | name2 | 1        | undefined |
| 3    | name3 | 3        | undefined |

第二个事务，执行第二次查询：

由于第三条数据的创建版本号为3，大于第二个事务的版本号2，因此第三条数据不会显示。

| id   | name  | 创建版本 | 删除版本  |
| ---- | ----- | -------- | --------- |
| 1    | name1 | 1        | undefined |
| 2    | name2 | 1        | undefined |

第四个事务创建，删除第二条数据，并提交：
此时第四个事务id为4，删除操作是由事务4操作，因此删除版本改为4。

| id   | name  | 创建版本 | 删除版本  |
| ---- | ----- | -------- | --------- |
| 1    | name1 | 1        | undefined |
| 2    | name2 | 1        | 4         |
| 3    | name3 | 3        | undefined |

在第二个事务中，执行第三次查询：

由于第二条数据的删除版本号为4，大于第二个事务的版本号2，因此第二条数据会显示。

| id   | name  | 创建版本 | 删除版本  |
| ---- | ----- | -------- | --------- |
| 1    | name1 | 1        | undefined |
| 2    | name2 | 1        | 4         |

第五个事务创建，更新第一条数据：

此时第五个事务ID为5，原来第一条数据（undo）的删除版本改为5，新增了一条数据，创建版本号为5。

| id   | name   | 创建版本 | 删除版本  |
| ---- | ------ | -------- | --------- |
| 1    | name1  | 1        | 5         |
| 2    | name2  | 1        | 4         |
| 3    | name3  | 3        | undefined |
| 1    | name11 | 5        | undefined |

可以看到同时出现了两条id为1的数据，实际上是因为在InnoDB 中，MVCC 是通过Undo log 实现的。

第一条数据实际记录在了undo log。



### LBCC

基于锁的并发控制 LBCC（LockBased Concurrency Control）。通过对事务操作的数据加锁的形式，使得一个事务执行时，其他事务不能对该事务操作的数据进行读写操作。该方法意味着不支持并发的读写操作，极大地影响操作数据的效率。

> 在InnoDB 中，MVCC 和锁是协同使用的，这两种方案并不是互斥的。

#### InnoDB 锁的基本类型

官网把锁分成了8 类。

* 两个行级别的锁（Shared and ExclusiveLocks）
* 两个表级别的锁（Intention Locks）称为锁的基本模式。

* Record Locks、Gap Locks、Next-Key Locks，这三个我们可以把它们理解为锁的算法，也就是分别在什么情况下锁定什么范围。



#### 锁的粒度

**表锁：**锁住一张表，

**行锁：**锁住表里面的一行数据。

* 表锁锁定粒度大于行锁。
* 表锁加锁效率大于行锁。——表锁只需要直接锁住表，而行锁则需要先从表里面去检索这一行数据，然后再锁住该行数据。
* 表锁的冲突概率大于行锁。—— 表锁住一张表的时候，其他任何一个事务都不能操作这张表。但是锁住了表里面的一行数据的时候，其他的事务还可以来操作表里面的其他没有被锁定的行，所以表锁的冲突概率更大。
* 表锁并发效率低于行锁。—— 由于表锁的冲突概率大于行锁，那么并发效率也会相应的低于行锁。

> InnoDB 支持行锁和表锁，而MyISAM 只支持表锁。



#### 共享锁

共享锁（Shared Locks ），是行级别的锁。获取一行数据的读锁以后，可以用来读取数据，所以又称为读锁。

一个事务获取了该行数据的读锁，其他事务同样可以获取该数据的读锁。

读锁加锁方式：

```sql
select …… lock in share mode;
```

读锁释放方式：事务结束。



#### 排它锁

排它锁（Exclusive Locks），是行级别的锁。获取一行数据的排它锁以后，可以用来操作（更新操作）数据，所以又称为写锁。

一个事务获取了一行数据的排它锁（前提是该数据没有其他事务已获取其共享锁或排它锁），其他的事务就不能再获取这一行数据的共享锁和排它锁。

写锁加锁方式：

* **自动加锁：**在操作数据的时候，包括增删改，都会默认加上一个排它锁。

* **手动加锁：**我们用一个FOR UPDATE 给一行数据加上一个排它锁，这个无论是在我们的代码里面还是操作数据的工具里面，都比较常用。下面是对查询的数据手动加写锁：

  ```sql
  SELECT ... FOR UPDATE;
  ```



#### 意向锁

意向锁，是表级别的锁。

意向锁是由数据库自己维护的。当我们给一行数据加上共享锁之前，数据库会自动在这张表上面加一个
意向共享锁。当我们给一行数据加上排它锁之前，数据库会自动在这张表上面加一个意向排它锁。

作用：

* 如果一张表有意向共享锁时，代表已有事务对该表数据加上了共享锁；如果一张表有意向排它锁时，代表已有事务对该表数据加上了排它锁。
* 如果我们要对一张表加锁，就需要确保没有事务对该表的数据加锁。如何确保？我们可以想到通过扫描该表所有数据是否加锁了，显而易见效率非常低。而意向锁就类似一种标识，表示该表没有数据加行锁。
* 如果要给表加写锁，前提是该表不能有意向锁（意向共享锁或意向排它锁）；如果要给表加读锁，前提是该表不能有意向排它锁。

加表锁方式：

```sql
-- 对user表加意向共享锁
LOCK TABLES user READ;
-- 对user表加意向排它锁
LOCK TABLES user WRITE;
```

释放表锁方式：

```sql
UNLOCK TABLES;
```



### 行锁原理

锁是用来解决事务对数据的并发访问的问题的。

对于InnoDB 的行锁，其锁住的不是数据，也不是字段，而是锁住索引。

对于InnoDB的表来说，每张表一定会有索引（可以看前面索引内容）所以得出结论：

1. 当加行锁时，没有使用索引，则会进行全表扫描，然后把每一个隐藏的聚集索引（隐藏的主键索引）都锁住。此时等同于表锁，对所有数据加锁。

案例：

User 表没有创建索引，然后在事务中对其加行锁：

```sql
begin;
SELECT * FROM `user` WHERE name = 'user1' FOR UPDATE;
```

此时，其锁住的是所有隐藏的聚集索引，导致其他事务对该表无法操作。



2. 当加行锁时，使用了辅助索引，由于辅助索引最终是找出主键值，再回表到主键索引查找数据，因此行锁锁住了对应辅助索引外，还根据该辅助索引的主键值，也锁住了对应的主键索引。

案例：

User 表的name字段创建辅助索引，然后在事务中对其加行锁：

```sql
begin;
SELECT * FROM `user` WHERE name = '1' FOR UPDATE;
```

此时，其锁住的是对应的辅助索引及对应的主键索引，导致其他事务不能对被锁住的索引的数据进行操作，例如：

```sql
select * from `user` where id = 1 FOR UPDATE;// blocked

UPDATE user SET name='2' WHERE name = '1';// blocked
```

> 因此在加锁时，应该注意是否 select 是否使用到索引，避免全表加锁。

### 锁的算法

![锁的算法](C:\Users\63190\Desktop\pics\锁的算法.jpg)

上面是表（主键索引）的主键值，我们把这每一条主键值叫做**记录（Record）**。

Record 之间相隔开的区间（没有数据），我们把它叫做**间隙（Gap）**，它是一个左开右开的区间。

间隙（Gap）连同它右边的记录（Record）组合一起叫做**临键的区间（Next-key）**，它是一个左开右闭的区间。

> 如果我的主键索引是字符串，实际会用ASCII 码来排序。



#### 记录锁（Record Locks）

当我们对于唯一性的索引（包括唯一索引和主键索引）使用等值查询，精准匹配到一条记录的时候，这个时候使用的就是记录锁。

例如：

```sql
SELECT * FROM 'user' WHERE id = 1 FOR UPDATE;
```

他只会锁住主键id = 1的这条记录的主键索引，此时对其他主键id加锁，不会冲突，因为其他主键id的主键索引没有被锁住。



#### 间隙锁（Gap Locks）

当我们查询的记录不存在，没有命中任何一个record，无论是用等值查询还是范围查询的时候，它使用的都是间隙锁。

例如：

```sql
-- id(4,7)之间没有数据
SELECT * FROM 'user' WHERE id > 4 AND id < 7 FOR UPDATE;
```

此时上面的查询的区间范围没有命中一条记录，就会使用间隙锁，对间隙（4,7）加锁。

间隙锁主要是阻塞插入insert，因此此时对id(4,7)之间无法插入数据。可以对已经加了间隙锁的间隙区间重复加间隙锁。

> Gap Lock 只在Repeatable Read （可重复读）隔离级别中存在。如果要关闭间隙锁，就是把事务隔离级别设置成Read Committed（已提交读）隔离级别，并且把 `innodb_locks_unsafe_for_binlog` 设置为ON。
>
> 这种情况下除了外键约束和唯一性检查会加间隙锁，其他情况都不会用间隙锁。



#### 临键锁（Next-Key Locks）

当使用了范围查询，不仅仅命中了Record 记录，还包含了Gap间隙，在这种情况下会使用临键锁，它是MySQL 里面默认的行锁算法，相当于记录锁加上间隙锁。

> 实际其他两种锁的算法是该算法的退化：
>
> * 唯一性索引，等值查询匹配到一条记录的时候，退化成记录锁。
> * 没有匹配到任何记录的时候，退化成间隙锁。

临键锁，锁住最后一个key 的下一个左开右闭的区间。

例如：

```sql
 -- 锁住(4,7]和(7,10]
select * from `user` where id > 5 and id <= 7 for update;
 -- 锁住(7,10]，(10,+∞)
select * from `user` where id > 8 and id <= 10 for update;
```



### 幻读解决

InnoDB 在 Repeatable Read（可重复读）隔离级别下，通过 MVCC 和临键锁配合使用可以解决幻读问题。

MVCC 保证了事务不会读取到其他事务插入的数据（未提交），因为各自都读取事务自己的快照。

给读取的数据加临键锁，保证了加锁之后读取期间其他事务不能插入数据（只能等待该事务提交后释放锁才能插入）。



## 总结

* **Read Uncommited 隔离级别：**不加锁。
* **Serializable 隔离级别：**所有的select 语句都会被隐式的转化为select ... in share mode（加读锁），会
  和update、delete 互斥（无法对加读锁的数据进行写入更新操作）。
* **Repeatable Read 隔离级别：**
  * 普通的select 使用快照读(snapshot read)，底层使用MVCC 来实现。
  * 加锁的select(select ... in share mode / select ... for update) 以及更新操作update, delete 等语句使用当前读（current read），底层使用记录锁、或者间隙锁、临键锁。
* **Read Committed 隔离级别：**
  * 普通的select 都是快照读，使用MVCC 实现。
  * 加锁的select 都使用记录锁，因为没有Gap Lock。

> 由于使用临键锁可以避免幻读的操作，得出以下结论（对于 InnoDB）：
>
> * RC 隔离级别在外键约束检查(foreign-key constraint checking)以及重复键检查(duplicate-key checking)时会使用间隙锁封锁区间。其余加锁的select只会用记录锁，因此会出现幻读的问题。
> * RR 对于加锁的 select 会使用记录锁、或者间隙锁、临键锁，因此解决了幻读的问题。
> * InnoDB 中只需要 RR 的隔离级别就解决了多事务并发的读一致性问题。



# 事务隔离级别选择

RU 和Serializable 肯定不能用。

RC 和RR 主要有几个区别：

1. RR 的间隙锁会导致锁定范围的扩大。

2. 条件列未使用到索引，RR 锁表（全表扫描，用到了间隙锁，锁住了隐藏主键索引的所有区间），RC 锁行（全表扫描，锁住了隐藏主键索引的所有记录）。

3. RC 的“半一致性”（semi-consistent）读可以增加update 操作的并发性。

   在RC 中，一个update 语句，如果读到一行已经加锁的记录，此时InnoDB 返回记录最近提交的版本，由MySQL 上层判断此版本是否满足update 的where 条件。若满足(需要更新)，则MySQL 会重新发起一次读操作，此时会读取行的最新版本(并加锁)。

实际上，如果能够正确地使用锁（避免不使用索引去加锁），只锁定需要的数据，用默认的RR 级别就可以了。



# 死锁

## 锁的释放

当事务结束（commit，rollback）、客户端连接断开时，会将获取到的锁释放。



## 锁的阻塞

当一个事务获取了锁，而其他事务需要获取该锁的时候，就会被阻塞等待该事务释放锁。

如果事务一直不释放锁，等待该锁的事务如果一直阻塞挂起，会占用大量计算机资源，造成严重性能问题，甚至拖跨数据库。

因此MySQL 通过设置一个参数来控制获取锁的等待时间，默认是50 秒：

```sql
show VARIABLES like 'innodb_lock_wait_timeout';
```



## 死锁

死锁演示：

| 事务1                                                 | 事务2                                     |
| ----------------------------------------------------- | ----------------------------------------- |
| begin;<br/>select * from user where id =1 for update; |                                           |
|                                                       | begin;<br/>delete from user where id =4 ; |
| update user set name= '44' where id =4 ;              |                                           |
|                                                       | delete from user where id =1 ;            |

此时事务1在获取主键id=4的锁的时候，由于该锁已经被事务2获取了，导致事务1阻塞等待。而此时事务2在获取主键id=1的锁的时候，由于该锁已经被事务1获取了，也导致事务2阻塞等待。最终形成了闭环（两个事务需要等待对方释放自己所需要的锁，才能释放已有的锁），即死锁。

InnoDB 对于死锁问题，采取了检测的机制（算法 wait-for graph），不会让死锁出现导致资源一直被占用。

实际上在事务1尝试获取主键id=4的锁的时候，检测到死锁，会主动结束事务（回滚），使得事务2获取了锁，执行下去。不会造成阻塞等待的情况。



死锁条件总结：

1. 锁是互斥的，同一时刻只能有一个事务持有这把锁
2. 其他的事务需要在这个事务释放锁之后才能获取锁，而不可以强行剥夺
3. 当多个事务形成等待环路的时候，即发生死锁。



## 查看锁信息（日志）

查看行锁的信息：

```sql
show status like 'innodb_row_lock_%';
```

* Innodb_row_lock_current_waits：当前正在等待锁定的数量；
* Innodb_row_lock_time ：从系统启动到现在锁定的总时间长度，单位ms；
* Innodb_row_lock_time_avg ：每次等待所花平均时间；
* Innodb_row_lock_time_max：从系统启动到现在等待最长的一次所花的时间；
* Innodb_row_lock_waits ：从系统启动到现在总共等待的次数。



InnoDB 还提供了三张表来分析事务与锁的情况：

```sql
-- 当前运行的所有事务，还有具体的语句
select * from information_schema.INNODB_TRX;
-- 当前出现的锁
select * from information_schema.INNODB_LOCKS;
-- 锁等待的对应关系
select * from information_schema.INNODB_LOCK_WAITS;
```



对于死锁的解决方法，实际可以通过直接kill掉事务对应的线程ID ，也就是INNODB_TRX 表中trx_mysql_thread_id。当然kill 这种操作指标不治本，我们应当从代码的逻辑角度去分析为什么会出现死锁，然后避免死锁的出现。



## 死锁的避免

1. 在程序中，操作多张表时，尽量以相同的顺序来访问（避免形成等待环路）；
2. 批量操作单张表数据的时候，先对数据进行排序（避免形成等待环路）；
3. 申请足够级别的锁，如果要操作数据，就申请排它锁；
4. 尽量使用索引访问数据，避免没有where 条件的操作，避免锁表；
5. 如果可以，大事务化成小事务；
6. 使用等值查询而不是范围查询查询数据，命中记录，避免间隙锁对并发的影响。
