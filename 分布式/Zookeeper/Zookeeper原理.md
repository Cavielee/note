Zookeeper 是一个高可靠的分布式协调中间件。



# 数据模型

![Zookeeper节点](C:\Users\63190\Desktop\pics\Zookeeper节点.png)

客户端可以通过 Zookeeper 中间件进行数据存储。

Zookeeper 数据模型实际类似于文件系统的层次化树形结构，即文件夹（节点）里面可以有子文件夹，子文件夹也可以有其子文件夹，以此类推。

ZNode 是 Zookeeper 的最小单元。每一个 ZNode 都可以存储数据和子节点。

通过节点可以存储数据，并且根据节点和子节点的特性可以解决分布式架构中的相关问题。



由于 `zookeeper` 是目录节点结构，在获取和创建节点时，必须要以`“/”` 开头，否则在获取节点时会报错 `Path must start with / character`。因此要获取某个子节点时，要输入其完整的目录结构。

> Znode 默认可存储最大数据量为 1MB。
>
> 一个节点的数据量不仅包含它自身存储数据，它的所有子节点的名字也要折算成Byte数计入，因此 Znode 的子节点数也不是无限的。



## 节点属性

一个`Znode` 节点不仅可以存储数据，还有一些其他特别的属性。

| 节点属性       | 注解                                                         |
| :------------- | :----------------------------------------------------------- |
| cZxid          | 该数据节点被创建时的事务Id                                   |
| mZxid          | 该数据节点被修改时最新的事务Id                               |
| pZxid          | 当前节点的父级节点事务Id                                     |
| ctime          | 该数据节点创建时间                                           |
| mtime          | 该数据节点最后修改时间                                       |
| dataVersion    | 当前节点版本号（每修改一次值+1递增）                         |
| cversion       | 子节点版本号（子节点修改次数，每修改一次值+1递增）           |
| aclVersion     | 当前节点acl版本号（节点被修改acl权限次数，每修改一次值+1递增） |
| ephemeralOwner | 临时节点标识，当前节点如果是临时节点，则存储的创建者的会话id（sessionId），如果不是，那么值=0 |
| dataLength     | 当前节点所存储的数据长度                                     |
| numChildren    | 当前节点下子节点的个数                                       |



### Zxid

`Znode` 节点状态改变会导致该节点收到一个 `zxid` 格式的时间戳，这个时间戳是全局有序的，Znode节点的建立或者更新都会产生一个新的。

每个znode节点都有3个 `zxid` 属性：

* `cZxid`：节点创建时间；
* `mZxid`：节点修改时间，与子节点无关；
* `pZxid`：节点或者该节点的子节点的最后一次创建或者修改时间，孙子节点无关。

`zxid`属性主要应用于`zookeeper`的集群，这个后边介绍集群时详细说。



### Version

`Znode` 属性中一共有三个版本号:

* `dataversion`：数据版本号；
* `cversion`：子节点版本号；
* `aclversion`：节点所拥有的ACL权限版本号。

`Znode` 中的数据可以有多个版本，如果某一个节点下存有多个数据版本，那么查询这个节点数据就需要带上版本号。

每当我们对 `Znode` 节点数据修改后，该节点的 `dataversion` 版本号会递增。

当客户端请求该 `Znode` 节点时，会同时返回节点数据和版本号。

当 `dataversion` 为  `-1` 的时候可以忽略版本进行操作。

对一个节点设置权限时 `aclVersion` 版本号会递增。



## 节点类型

`zookeeper` 有四种类型的 `Znode`，在用客户端 `client` 创建节点的时候需要指定类型。



### 持久化节点

PERSISTENT：持久化目录节点 。

客户端 client 创建节点后，与 zookeeper 断开连接该节点将被持久化，当 client 再次连接后节点依旧存在。



### 持久化有序节点

PERSISTENT_SEQUENTIAL：持久化顺序节点。

客户端 client 创建节点后，与 zookeeper 断开连接该节点将被持久化，再次连接节点还存在。zookeeper 会给持久化有序目录中的节点名称进行顺序编号，例如 `/lock/`目录下创建三个节点，会得到如下节点名称：/lock/0000000001、/lock/0000000002、/lock/0000000003。



### 临时节点

EPHEMERAL：临时目录节点。

客户端 client 与 zookeeper 断开连接后，该节点即会被删除。



### 临时有序节点

EPHEMERAL_SEQUENTIAL：临时顺序节点。

客户端 client 与 zookeeper 断开连接后，该节点被删除，会给该节点名称进行顺序编号，例如：/lock/0000000001、/lock/0000000002、/lock/0000000003。



### 容器节点

CONTAINER：当子节点都被删除后， Container 节点也会随即删除。

### 限时节点

PERSISTENT_WITH_TTL：超过 TTL 未被修改，且没有子节点，就会被删除

PERSISTENT_SEQUENTIAL_WITH_TTL：客户端断开连接后不会自动删除 Znode ，当该 Znode 没有子 Znode 且在给定 TTL 时间内无修改，该 Znode 将会被删除；

> TTL 单位是毫秒，必须大0 且小于或等于EphemeralType.MAX_TTL



## 节点的 ACL 权限控制

ACL（Access Control List）—— 节点的权限控制。

为了保证 zookeeper 中的数据的安全性，避免误操作带来的影响，通过 `ACL` 机制来解决 `Znode` 节点的访问权限问题，要注意的是 `zookeeper` 对权限的控制是基于 `znode` 级别的，也就说节点之间的权限不具有继承性，即子节点不继承父节点的权限。

`zookeeper` 中设置 ACL 权限的格式由 `<schema>:<id>:<acl>` 三段组成。

**schema** ：表示授权的方式

- `world`：表示任何人都可以访问。（默认权限）
- `auth`：只有认证的用户可以访问
- `digest`：使用 username:password 用户密码生成 MD5 哈希值作为认证 ID
- `host/ip`：使用客户端主机IP地址来进行认证

**id**：权限的作用域，用来标识身份，依赖于 schema 选择哪种方式。

**acl**：给一个节点赋予哪些权限，节点的权限有 create、delete、write、read、admin 统称 `cdwra`。



### world 授权方式

world 权限是 `znode` 节点默认权限，表示任何人都可以访问。



### auth 授权方式

schema 用 `auth` 授权表示只有认证后的用户才可以访问，那么首先就需要添加认证用户，添加完以后需要对认证的用户设置ACL权限。

auth 设置用户密码是明文。

```sh
# 添加 auth 用户，格式为：用户名/用户密码
addauth digest user:password
# 设置用户 user 的 acl 权限
setAcl /test auth:user:crdwa
```



### digest 授权方式

用户名：密码方式授权是针对单个特定用户，这种方式是不需要先添加认证用户的。

如果在代码中使用 zookeeper 客户端设置ACL，那么密码是明文的，但若是 zk.cli 等客户端操作就需要将密码进行 `sha1` 及 `base64` 处理。

可以使用 Zookeeper 提供的 DigestAuthenticationProvider 类生成加密密码。



### ip 授权方式

通过对特定的IP地址，也可以是一个 IP 段进行授权。



# 集群（高可用）

为了防止单点故障，实现 Zookeeper 的高可用，因此 Zookeeper 也提供集群模式。

ZAB 协议是为分布式协调服务 Zookeeper 专门设计的一种支持 **崩溃恢复** 的 **原子广播** 协议。

基于该协议，Zookeeper 实现了一种 **主备模式** 的系统架构来保持集群中各个副本之间数据一致性。

详细可以从分布式一致性中了解 ZAB 协议工作原理。



## 顺序一致性

Zookeeper 是一种顺序一致性模型，它是比最终一致性更强一致性的模型。

### 最终一致性模型缺点

假设 Zookeeper 是最终一致性模型，此时对于三个节点（一个 Leader，两个 Follower），对于数据x的更新，客户端某一时刻读取该数据x时，可能会存在三种情况：

1. 访问 Leader 节点读取数据x，此时返回的是最新值。
2. 访问 Follower 节点，该 Follower 节点已从 Leader 节点同步最新值，此时返回的是最新值。
3. 访问 Follower 节点，该 Follower 节点由于网络原因（延迟）还未从 Leader 节点同步最新值，此时返回的是旧值。

客户端的操作由于访问的节点时间不同，节点的数据同步状态不同，从而导致获取到的值可能不同。

**情景一：多个客户端访问同一数据**

像上述的情况下，如果多个客户端同时访问数据x，那么此时多个客户端获取到的结果可能不一样。为了避免该问题，多个客户端在访问该数据前，可以执行 sync 方法，强制同步数据，确保访问的节点返回的数据是最新值。

**情景二：一个客户端多次访问同一数据**

像上述的情况下，如果单客户端多次访问数据x，那么此时取到的结果可能不一样，因为访问了不同的节点。为了避免该问题，Zookeeper 每次连接节点成功时都会记录该节点的 Zxid。

如果客户端断开连接后，和新的节点重新建立连接，会首先判断该节点的 Zxid 是否小于之前记录的 Zxid，如果小于，则会连接失败（因为意味着当前尝试连接的节点数据比之前的旧），从而避免了访问不同节点的同一数据造成获取的数据不一致。即通过 Zxid 保证了顺序一致性。



# watcher 机制

`watcher` 是 `zooKeeper` 中一个非常核心功能 ，客户端 `watcher`  可以监控节点的数据变化以及它子节点的变化，一旦这些状态发生变化，zooKeeper 服务端就会通知所有在这个节点上设置过 `watcher` 的客户端 ，从而每个客户端都很快感知，它所监听的节点状态发生变化，而做出对应的逻辑处理。



## watcher 类型

watcher 类型分为两种：

* **DataWatches**：znode节点的数据变更从而触发 `watch` 事件，触发条件`getData()`、`exists()`、`setData()`、 `create()`。

* **Child Watches**：znode 的子节点发生变更触发的 watch 事件，触发条件 `getChildren()`、 `create()`。

当调用 `delete()` 方法删除 znode 时，则会同时触发 `Data Watches` 和 `Child Watches`，如果被删除的节点还有父节点，则父节点会触发一个 `Child Watches`。

## watcher 特性

`watch` 对节点的监听事件是一次性的。客户端在指定的节点设置了监听 `watch`，一旦该节点数据发生变更通知一次客户端后，客户端对该节点的监听事件就失效了。

如果还要继续监听这个节点，就需要我们在客户端的监听回调中，再次对节点的监听 `watch` 事件设置为 `True`。否则客户端只能接收到一次该节点的变更通知。



## 事件类型

|        zookeeper 事件         |                           事件含义                           |
| :---------------------------: | :----------------------------------------------------------: |
|     EventType.NodeCreated     |               当监听节点被创建时，该事件被触发               |
| EventType.NodeChildrenChanged | 当监听节点的直接子节点被创建、被删除、子节点数据发生变更时，该事件被触发。 |
|   EventType.NodeDataChanged   |           当监听节点的数据发生变更时，该事件被触发           |
|     EventType.NodeDeleted     |              当监听节点被删除时，该事件被触发。              |
|        EventType.None         | 当 zookeeper 客户端的连接状态发生变更时，即 KeeperState.Expired、KeeperState.SyncConnected、KeeperState.AuthFailed |



# Zookeeper 分布式协调

通过 Zookeeper 的特性，可以实现分布式协调，如分布式锁、服务注册中心、分布式队列、配置中心、选举等功能。



## 分布式锁

**方案一**

1. 通过对指定路径创建一个临时节点来表示锁。
   * 由于节点只会创建一次，其他节点则会创建失败，因此确保了只会有一个线程获取到锁。
   * 临时节点确保了即使手动释放锁失败（删除节点）也会在会话结束时自动释放锁，从而防止死锁。
2. 创建锁失败的客户端会对节点注册一个 Watch 进行监听。
3. 当节点被删除时（锁释放），会发送事件通知对应的所有 Watch。
4. 客户端收到节点删除事件后会进行重新竞争锁（即重新发起节点创建）。

缺点：

由于只会有一个线程获取到锁，而其他线程都获取失败。一旦锁释放后，所有线程都会收到事件而去争取锁，即 ”惊群效应“，导致不必要的系统资源浪费。

**方案二**

基于方案一的优化：

1. 通过对指定路径创建一个临时有序节点来表示锁。
   * 临时节点确保了即使手动释放锁失败（删除节点）也会在会话结束时自动释放锁，从而防止死锁。
   * 节点有序的机制确保了按照节点的序号依次获得锁资源。
2. 规定当前路径下序号最小的节点为获得锁的节点，其他序号的节点监听紧跟其前面序号的节点。
3. 当节点被删除时（锁释放），会发送事件通知紧跟其后面序号的节点。
4. 客户端收到节点删除事件后（只会有一个客户端获取到该事件），意味着此时获取到了锁资源，可以进行操作。

> Zookeeper 的 Curator 客户端提供了分布式锁的实现，详情可以看 Curator 相关笔记。

## Leader 选举

集群中一般需要区分主节点和从节点，主节点主要处理集群中的事务请求，从节点只能处理读请求。

因此需要一种机制能够从集群中选举出主节点，而且当主节点失效不可用时，可以从所有的从节点中选出新的主节点。

可以使用 Zookeeper 实现 Leader 选举，其原理和分布式锁一致：

1. 通过对指定路径创建一个临时有序节点。
   * 临时节点确保了Master节点不可用（宕机）时，会自动的将节点删除。
   * 节点有序的机制确保了按照节点的序号依次成为 Master 节点。
2. 规定当前路径下序号最小的节点为 Master 节点，其他序号的节点监听紧跟其前面序号的节点。
3. 当节点被删除时（Master 不可用），会发送事件通知紧跟其后面序号的节点。
4. 客户端收到节点删除事件后（只会有一个客户端获取到该事件），意味着需要重新选举出 Master 节点，此时收到该请求的从节点就会成为新的 Master 节点。

> Zookeeper 的 Curator 客户端提供了 Leader 选举的实现，详情可以看 Curator 相关笔记。

## 服务注册中心

在分布式架构中，服务调用需要进行远程网络通信。因此需要知道各个服务集群节点的地址信息（服务不一定会有集群，可能只是单节点）。

而 Zookeeper 可以作为第三方存储中间件去管理服务地址信息，服务提供者只需将自己地址信息注册（存储）到 Zookeeper 中，而服务消费者从 Zookeeper 中获取服务提供者地址信息，并且 Zookeeper 提供事件机制，用于当服务提供者不可用时主动通知服务消费者。

![Zookeeper服务注册中心](C:\Users\63190\Desktop\pics\Zookeeper服务注册中心.jpg)

- **服务注册：** 服务提供者（`Provider`）启动时，会向 `zookeeper服务端` 注册服务信息，也就是创建一个节点，例如：用户注册服务`com.xxx.user.register`，并在节点上存储服务的相关数据（如服务提供者的 ip 地址、端口等）。
- **服务发现：** 服务消费者（`Consumer`）启动时，根据自身配置的依赖服务信息，向`zookeeper服务端`获取注册的服务信息并设置 `watch监听`，获取到注册的服务信息之后，将服务提供者的信息缓存在本地，并进行服务的调用。
- **服务通知：** 一旦服务提供者因某种原因宕机不再提供服务之后，客户端与`zookeeper`服务端断开连接，`zookeeper`服务端上服务提供者对应服务节点会被删除（例如：用户注册服务`com.xxx.user.register`），随后`zookeeper`服务端会异步向所有消费用户注册服务`com.xxx.user.register`，且设置了`watch监听`的服务消费者发出节点被删除的通知，消费者根据收到的通知拉取最新服务列表，更新本地缓存的服务列表。
