# 事务

指当一个业务涉及一系列操作（对多个数据库表操作），我们对这一系列作为一个整体（事务）完成。该事务中的所有操作要么全部成功，要么全部失败。



# 分布式事务

分布式事务顾名思义就是要在分布式系统中实现事务，它其实是由多个本地事务组合而成。



## 分布式事务情景

#### 数据库分布式事务

数据库本身提供事务，确保 ACID 的特性。数据库默认事务粒度为每条 SQL 语句建立一个事务，并在 SQL 语句执行完后自动提交或者执行失败进行回滚。

**（一）分库**

业务处理的数据库操作落在多个数据库中，而数据库提供的事务本身只能确保自己数据库操作的 ACID 特性，无法干涉其他数据库。

![事务场景-分库](C:\Users\63190\Desktop\pics\事务场景-分库.png)

**（二）数据分片**

使用分库分表中间件后，一个业务的多个数据库操作可能落在多个数据库或一个数据库中的多张表。对于业务逻辑而言，底层的数据分片情况是不透明的，因此也没有办法依赖于数据库提供的单机事务机制。

![事务场景-分片](C:\Users\63190\Desktop\pics\事务场景-分片.png)

**（三）微服务架构**

在微服务架构中，一个业务的处理可能涉及多个服务应用的调用，而不同的服务应用会使用不同的数据源。在这种情况下，数据库提供的单机事务机制，仅仅能保证其中单一环节的 ACID 特性，没有办法延伸到全局。

![事务情景-微服务](C:\Users\63190\Desktop\pics\事务情景-微服务.png)



#### 微服务分布式事务

由于微服务化后，一个业务请求可能涉及底层多个远程服务调用。由于网络通信存在不可靠，导致多个远程服务调用中可能存在障碍。当通过网络请求其他服务的接口时，往往会得到三种结果：正确、失败和超时，无论是成功还是失败，我们都能得到唯一确定的结果，**超时代表请求的发起者不能确定接受者是否成功处理了请求**，这也是造成诸多问题的诱因。

因此需要分布式事务控制所有服务接口调用成功后进行事务提交，当某个服务接口失败或异常时会对事务所有操作进行回滚。



# 事务日志

无论是事务还是分布式事务实现原子性都无法避免对 **持久存储** 的依赖，事务使用磁盘上的日志去记录执行的过程以及上下文，这样无论是需要 **回滚** 还是 **补偿** 都可以通过日志追溯。每一条事务日志中都包含事务的 ID、当前被修改的元素、变动前以及变动后的值。

通过事务日志可以对事务进行回滚，回滚到事务发生之前的状态，从而保证原子性。

在事务操作执行前，首先会写入事务日志并刷新到磁盘上（写日志的操作由于是追加的所以非常快），从而保证持久性。

例如在 MySQL 最常见的存储引擎 InnoDB 中，事务日志其实有两种，一种是回滚日志（undo log），另一种是重做日志（redo log），其中前者保证事务的原子性，后者保证事务的持久性，两者可以统称为事务日志。

分布式事务会依赖数据库、Zookeeper 或者 ETCD 等服务追踪事务的执行过程



# 分布式一致性协议

## 2PC

二阶段提交：Two-phase Commit 。

两阶段提交是一种使分布式系统中所有节点在进行事务提交时保持一致性而设计的一种协议。

两阶段提交分为两个阶段：**投票阶段** 和 **提交阶段**。

**投票阶段：**协调者（Coordinator）会向事务的参与者（Cohort）询问是否可以执行操作的请求，并等待其他参与者的响应，参与者会执行相对应的事务操作并**记录重做和回滚日志**，所有执行成功的参与者会向协调者发送 `AGREEMENT` 或者 `ABORT` 表示执行操作的结果。

**提交阶段：**当所有的参与者都返回了确定的结果（同意或者终止）时，两阶段提交就进入了提交阶段，协调者会根据投票阶段的返回情况向所有的参与者发送提交或者回滚的指令。

当事务的所有参与者都决定提交事务时，协调者会向参与者发送 `COMMIT` 请求，参与者在完成操作并释放资源之后向协调者返回完成消息，协调者在收到所有参与者的完成消息时会结束整个事务；与之相反，当有参与者决定 `ABORT` 当前事务时，协调者会向事务的参与者发送回滚请求，参与者会根据之前执行操作时的 **回滚日志** 对操作进行回滚并向协调者发送完成的消息，在提交阶段，无论当前事务被提交还是回滚，所有的资源都会被释放并且事务也一定会结束。



**存在的问题：**

- 阻塞式事务。当某个参与者发生故障或执行时间很长，其他参与者必须等待该参与者返回响应给协调者，协调者才能发送执行提交/失败命令给参与者。
  - 解决方案：可以给事务设置一个超时时间，如果某个参与者一直不响应，那么认为事务执行失败。
- 数据不一致。协调者收到参与者1的失败通知，还没来得急通知其他参与者进行回滚就发生故障，此时重启后没有了参与者1的信息而根据其他参与者成功通知进行了提交事务。
  - 解决方案：将操作日志同步到备用协调者，让备用协调者接替后续工作。



## 3PC

三阶段提交：Three-phase Commit 。是二阶段提交的优良版协议。

为了解决两阶段提交在协议的一些问题，三阶段提交引入了**超时机制** 和 **准备阶段**。

1. 准备阶段：协调者询问参与者是否可以执行事务。
2. 执行事务：若所有参与者表示可以执行事务，则会发送 ACK 让参与者执行事务。
3. 提交阶段：根据参与者事务执行结果来判断是否提交事务/回滚事务。



3PC 好处：

* 加入了超时机制，若协调者或参与者在规定时间内没有接收到来自其他节点的响应，就会根据当前状态选择提交或回滚事务。
* 当参与者发送了 ACK 之后长时间没收到协调者的响应，则会默认提交事务（因为有了第一步准备阶段，当进入第二阶段时，就证明其他节点表明都可以执行事务。因此即使协调者宕机没响应，也不会影响参与者提交事务。）



# 分布式事务类型

分布式事务分为两种：

**（一）传统分布式事务**

传统分布式事务实现方式为 **XA 事务**，例如Atomikos。

传统分布式事务实际是基于 2PC 一致性协议，通过引入事务协调者去管理控制各个子事务的提交或回滚，从而实现数据强一致性。

**（二）柔性事务**

柔性事务是基于 BASE 理论和 CAP 理论实现的分布式事务，保证数据最终一致性。

柔性事务实现方式有很多种：

1. Saga
2. 事务消息（基于消息中间件）
3. TCC（Try-Confirm-Cancel）tcc-transaction
4. 最大努力通知，通过消息中间件向其他系统发送消息（重复投递+定期校对）



**二者区别：**

|          | 传统分布式事务 | 柔性事务                     |
| -------- | -------------- | ---------------------------- |
| 业务改造 | 无             | 有                           |
| 一致性   | 强一致性       | 最终一致                     |
| 回滚     | 支持           | 实现回退接口                 |
| 隔离性   | 支持           | 放弃隔离性或实现资源锁定接口 |
| 并发性能 | 低             | 高                           |
| 适合场景 | 低并发、短事务 | 高并发、长事务               |



## 全局事务（XA 事务）

全局事务基于DTP模型实现。DTP是一种分布式事务模型，它规定了要实现分布式事务，需要三种角色：

- **AP：Application 应用系统（应用）**

  它就是我们开发的业务系统，在我们开发的过程中，可以使用资源管理器提供的事务接口来实现分布式事务。

- **TM：Transaction Manager 事务管理器（事务协调者）**

- - 分布式事务的实现由事务管理器来完成，它会提供分布式事务的操作接口供我们的业务系统调用。这些接口称为TX接口。
  - 事务管理器还管理着所有的资源管理器，通过它们提供的XA接口来同一调度这些资源管理器，以实现分布式事务。
  - DTP只是一套实现分布式事务的规范，并没有定义具体如何实现分布式事务，TM可以采用2PC、3PC、Paxos等协议实现分布式事务。

- **RM：Resource Manager 资源管理器**

- - 能够提供数据服务的对象都可以是资源管理器，比如：数据库、消息中间件、缓存等。大部分场景下，数据库即为分布式事务中的资源管理器。
  - 资源管理器能够提供单数据库的事务能力，它们通过XA接口，将本数据库的提交、回滚等能力提供给事务管理器调用，以帮助事务管理器实现分布式的事务管理。
  - XA是DTP模型定义的接口，用于向事务管理器提供该资源管理器(该数据库)的提交、回滚等能力。
  - DTP只是一套实现分布式事务的规范，RM具体的实现是由数据库厂商来完成的。

### XA 接口

数据库提供 XA 接口，允许外部去控制事务的提交/回滚。



### 原理

XA 事务是基于 2PC 分布式一致性协议实现的，因此 XA 事务能够保证较强的一致性。

事务管理器为协调者，而资源管理器就是分布式事务的参与者。

- 资源管理器提供了访问事务资源的能力，数据库就是一种常见的资源管理器，它能够提交或者回滚其管理的事务；
- 事务管理器协调整个分布式事务的各个部分，它与多个资源管理器通信，分别处理他们管理的事务，这些事务都是整体事务的一个分支。



### 实现

基于DTP模型实现分布式事务的中间件为 Atomikos。

### 缺点

由于 XA 基于 2PC 分布式一致性协议实现的，因此会存在事务长时间没有收到协调者的 COMMIT 或者 ROLLBACK。而在 MySQL XA 的执行过程中会对相应的资源加锁，阻塞其他事务对该资源的访问，因此会对数据库造成比较严重的影响。



## Saga

两阶段提交是保证事务强一致性的方案。

但在实际业务场景下，我们其实只需要保证业务的最终一致性，即软一致性。在一定的时间内，多个系统中的数据不一致是可以接受的，在过了一段时间之后，所有系统都会返回一致的结果。

Saga 是一种实现 BASE 理论补偿式的分布式事务方案。

Saga 将一系列的分布式操作转化成了一系列的本地事务，通过流式处理方式，在每一个服务事务处理后会发送时间触发下一个服务事务处理。一旦事务链中某个事务失败或异常时，会触发一系列补偿机制从而回滚之前本地事务造成的副作用。



### LLT

LLT——长事务（Long Lived Transaction）会对一些数据库资源持有相对较长的一段时间，这会严重地影响其他正常数据库事务的执行。事务越长并且越复杂，那么这个事务由于异常而被回滚以及死锁的可能性就会逐渐增加，Saga 会将一个 LLT 分解成多个短事务，能够非常明显地降低事务被回滚的风险。



### 协同与编排

Saga 模式开发分布式事务时，有两种协调不同服务的方式，一种是协同（Choreography），另一种是编排（Orchestration）：

**协同模式**

实际上是一种去中心化的模式，即事务的执行过程是一个流的形式进行的。每一个本地的事务都会触发一个其他服务中的本地事务的执行。

当我们选择使用协同的方式处理事务时，服务之间的通信其实就是通过事件进行的，每一个本的事务最终都会向服务的下游发送一个新的事件，既可以是消息队列中的消息，也可以是 RPC 的请求，只是下游提供的接口需要保证幂等和重入。

缺点：管理以及调试上的不便，当需要追踪一个业务的执行过程时就需要跨越多个服务进行，增加了维护的成本。

**编排模式**

实际上是一种中心化的模式，即需要引入中心化的协调器节点，通过一个 Saga 对象来追踪所有的子任务的调用情况，根据任务的调用情况决定是否需要调用对应的补偿方案，并在网络请求出现超时时进行重试。

缺点：需要处理协调器单点故障问题。



### 下游约束

当我们选择使用 Saga 对分布式事务进行开发时，会对分布式事务的参与者有一定的约束，每一个事务的参与者都需要保证：

1. 提供接口和补偿副作用的接口；
2. 接口支持重入并通过全局唯一的 ID 保证幂等；

这样我们就能够保证一个长事务能够在网络通信发生超时时进行重试，同时在需要对事务进行回滚时调用回滚接口达到我们的目的。



## 事务消息

假设有A和B两个系统，分别可以处理任务A和任务B。此时系统A中存在一个业务流程，需要执行任务A和任务B，并且要确保两个任务要在在同一个事务中处理。

基于消息队列实现事务消息型的分布式事务如下：



**分布式事务执行成功**

![分布式事务（消息队列）](C:\Users\63190\Desktop\pics\分布式事务（消息队列）.png)

1. 系统A执行任务A前，首先向消息中间件发送一条消息（执行任务B）；
2. 消息中间件收到后将该条消息持久化，但并不投递给系统B（此时系统B不知道该条消息的存在）；
3. 消息中间件持久化成功后，便向系统A返回一个确认应答；
4. 系统A收到确认应答后，则可以开始处理任务A；
5. 任务A处理完成后，向消息中间件发送Commit请求。该请求发送完成后，对系统A而言，该事务的处理过程就结束了，此时它可以处理别的任务了。
6. 消息中间件收到Commit指令后，便向系统B投递该消息，从而触发任务B的执行；
7. 当任务B执行完成后，系统B向消息中间件返回一个确认应答，告诉消息中间件该消息已经成功消费，此时，这个分布式事务完成。



> 1. 消息中间件扮演者分布式事务协调者的角色。
> 2. 由于任务A和任务B不是同时执行，因此在一定时间差内，整个系统处于数据不一致的状态，但数据最终一致。



**分布式事务执行失败**

在上面第四步时，执行处理任务A可能会失败，因此需要回滚操作（将之前发布的消息丢弃），流程如下：

![分布式事务（消息队列）回滚](C:\Users\63190\Desktop\pics\分布式事务（消息队列）回滚.png)

1. 系统A在处理任务A时失败，那么就会向消息中间件发送Rollback请求。系统A发完之后便可以认为回滚已经完成，它便可以去做其他的事情。
2. 消息中间件收到回滚请求后，直接将该消息丢弃，而不投递给系统B，从而不会触发系统B的任务B。



由于回滚操作后，此时系统又处于一致性状态，因为任务A和任务B都没有执行。



### 存在问题

由于网络不可靠，因此会存在以下问题：

**（一）Commit和Rollback请求丢失**

系统发送给消息中间件的 Commit 和 Rollback 请求可能因为网络原因丢失。

Commit 丢失会导致执行了任务A，而任务B无法执行（消息中间件没有收到指令将消息进行投递给系统B），从而导致数据不一致。

Rollback 丢失会导致消息中间件的消息没有被丢弃，导致数据不一致。

而消息中间件的超时回查机制正是解决上述丢失问题。

![消息队列超时回查机制](C:\Users\63190\Desktop\pics\消息队列超时回查机制.png)

系统A 除了实现正常的业务流程外，还需提供一个事务询问的接口，供消息中间件调用。当消息中间件收到一条事务型消息后便开始计时，如果到了超时时间也没收到系统 A 发来的 Commit 或 Rollback 指令的话，就会主动调用系统 A 提供的事务询问接口询问该系统目前的状态。该接口会返回三种结果：

- 提交：表示消息中间件要将消息投递给系统B。
- 回滚：表示消息中间件要将该消息丢弃。
- 处理中：表示消息中间件需要继续询问结果。

> 上游系统只需要发送Commit/Rollback指令给消息中间件后，就可以处理其他任务，无需阻塞等待消息中间件对该指令的响应。而消息中间件的超时询问机制是上述做法的保证，保证了上游系统的Commit/Rollback指令不会丢失，导致数据不一致情况。

**（二）消息投递失败**

由于网络原因，消息投递给下游系统的过程可能存在不可靠的情况：

1. 消息中间件往下游系统投递后，投递消息丢失。
2. 下游系统收到消息后执行完毕，返回响应给消息中间件，响应丢失。

为了防止这两种情况，需要消息中间件提供一种超时重传的机制，当没有收到下游系统返回的响应时，消息中间件会重新投递消息给下游系统。需要注意两个点：

1. 由于超时机制，下游系统可能多次收到消息，因此需要保证消息的幂等性，即多次执行消息不会有影响。
2. 超时机制不能一直重试投递，应该规定一定时间间隔重新投递一次，重试次数超过一定次数时，应该进行人工干预。

![消息队列超时机制-1](C:\Users\63190\Desktop\pics\消息队列超时机制-1.png)

为什么是失败重试而不是回滚？

一般来说失败的原因绝大多数是网络原因，可能是网络丢包，此时重试后一般都会成功。失败重试超过次数后，此时可以考虑对应的补偿机制。

而回滚操作的话，首先需要上游系统预先提供回滚接口，而且一般来说业务调用执行链会涉及多个业务系统，因此意味着每个系统都需要提供回滚接口，这无疑增加了额外的开发成本，业务系统的复杂度也将提高。对于一个业务系统的设计目标是，在保证性能的前提下，最大限度地降低系统复杂度，从而能够降低系统的运维成本。

> 不知大家是否发现，上游系统A向消息中间件提交Commit/Rollback消息采用的是异步方式，也就是当上游系统提交完消息后便可以去做别的事情，接下来提交、回滚就完全交给消息中间件来完成，并且完全信任消息中间件，认为它一定能正确地完成事务的提交或回滚。然而，消息中间件向下游系统投递消息的过程是同步的。也就是消息中间件将消息投递给下游系统后，它会阻塞等待，等下游系统成功处理完任务返回确认应答后才取消阻塞等待。为什么这两者在设计上是不一致的呢？

消息中间件和上游系统的通信采用异步方式。

上游系统通知消息中间件发布消息后就会继续处理其他任务，由消息中间件异步执行剩余的操作。从而提高上游系统的用户体验，降低用户等待时间。并且由于异步通信可能导致丢失问题，因此使用消息中间件的超市询问机制解决该问题。

消息中间件和下游系统的通信采用同步方式。

异步能提升系统性能，但随之会增加系统复杂度；而同步虽然降低系统并发度，但实现成本较低。因此，在对并发度要求不是很高的情况下，或者服务器资源较为充裕的情况下，我们可以选择同步来降低系统的复杂度。
我们知道，消息中间件是一个独立于业务系统的第三方中间件，它不和任何业务系统产生直接的耦合，它也不和用户产生直接的关联，它一般部署在独立的服务器集群上，具有良好的可扩展性，所以不必太过于担心它的性能，如果处理速度无法满足我们的要求，可以增加机器来解决。





## 最大努力通知（定期校对）

最大努力通知也被称为定期校对，该方案需要消息中间件的参与，其过程如下：

![分布式事务—最大努力通知](C:\Users\63190\Desktop\pics\分布式事务—最大努力通知.png)

1. 上游系统处理完任务A后，会将任务B执行消息放到本地消息表（持久化），这两个步骤要在同一个事务中。
2. 消息本地持久化后，会将该消息发布到消息中间件，并等待消息中间件返回响应，确保消息中间件成功持久化这条消息，然后上游系统即可处理其他任务；
3. 消息中间件收到消息后，会将消息同步投递给相应的下游系统，并触发下游系统的任务执行；
4. 当下游系统处理成功后，向消息中间件反馈确认应答，消息中间件便可以将该条消息删除，从而该事务完成。



### 存在问题

由于网络不可靠，因此在实际中可能会存在以下问题：

**（一）上游系统向消息中间件发送消息失败**

通过本地消息表持久化消息，从而保证消息即使因网络等问题发布到消息中间件失败，也可以进行失败重试，继续尝试发布消息到消息中间件。如果达到重试上限仍然发送失败，那就意味着消息中间件出现严重的问题，此时也只有人工干预才能解决问题。

通过将执行任务和本地持久化消息放在同一个事务中，保证本地持久化消息失败就会回滚，确保数据一致性。

**（二）消息中间件向下游系统投递消息失败**

消息中间件具有重试机制，可以在消息中间件中设置消息的重试次数和重试时间间隔，对于网络不稳定导致的消息投递失败的情况，往往重试几次后消息便可以成功投递。

如果超过了重试的上限仍然投递失败，那么消息中间件不再投递该消息，而是记录在失败消息表中，消息中间件需要提供失败消息的查询接口，下游系统会定期查询失败消息，并将其消费，这就是所谓的 **定期校对**。

如果重复投递和定期校对都不能解决问题，往往是因为下游系统出现了严重的错误，此时就需要人工干预。



**总结**

对于不支持事务型消息的消息中间件，如果要实现分布式事务的话，就可以采用这种方式。它能够通过 **重试机制** + **定期校对** 实现分布式事务，但相比于消息队列方式，它达到数据一致性的周期较长，而且还需要在上游系统中实现消息重试发布机制，以确保消息成功发布给消息中间件，这无疑增加了业务系统的开发成本，使得业务系统不够纯粹，并且这些额外的业务逻辑无疑会占用业务系统的硬件资源，从而影响性能。

因此，尽量选择支持事务型消息的消息中间件来实现分布式事务，如 RocketMQ。



## TCC 补偿型分布式事务

TCC即为Try Confirm Cancel，它属于补偿型分布式事务。TCC实现分布式事务一共有三个步骤：

- Try：尝试待执行的业务。实际为预留执行的业务所需要的资源，判断业务是否执行。
- Confirm：执行业务。开始执行业务，由于 Try 阶段已经完成了一致性检查，因此本过程直接执行，而不做任何检查。并且在执行的过程中，会使用到 Try 阶段预留的业务资源。
- Cancel：取消执行的业务。若业务执行失败，则进入 Cancel 阶段，它会释放所有占用的业务资源，并回滚Confirm 阶段执行的操作。



以下为转账的例子：

> 假设用户A用他的账户余额给用户B发一个100元的红包，并且余额系统和红包系统是两个独立的系统。

- Try 阶段

- - 创建一条转账流水，并将流水的状态设为**交易中**
  - 将用户A的账户中扣除100元（预留业务资源）
  - Try成功之后，便进入Confirm阶段
  - Try过程发生任何异常，均进入Cancel阶段

- Confirm 阶段

- - 向B用户的红包账户中增加100元
  - 将流水的状态设为**交易已完成**
  - Confirm过程发生任何异常，均进入Cancel阶段
  - Confirm过程执行成功，则该事务结束

- Cancel 阶段

- - 将用户A的账户增加100元
  - 将流水的状态设为**交易失败**



实际上 TCC 和 基于 2PC 全局事务很相似。只是全局事务是在 DB 层的分布式事务，而 TCC 是基于业务层面的分布式事务。TCC 需要开发者针对每一个业务对应设计 Try、Confirm、Cancel 的逻辑代码。

### 基于RM本地事务来实现全局事务

TCC 业务在执行时，会访问资源管理器（Resource Manager，下文简称RM）来存取数据。

如果 RM 没有提供本地事务的话，会出现在 Cancel 逻辑中需要对多个数据存储操作进行回滚，而每个回滚操作可能会失败，因此也需要对失败的情况进行补偿逻辑处理，会导致补偿死循环。其根本原因就是无法确保数据回滚操作一定能执行成功。

因此 TCC 需要 RM 本地事务来确保数据回滚操作一定会执行成功，而开发者就不需要考虑数据回滚失败的情况。



### Confirm/Cancel 服务的幂等性保障

在 TCC 事务模型中，Confirm/Cancel 业务可能会被重复调用，其原因很多。比如，全局事务在提交/回滚时会调用各 TCC 服务的 Confirm/Cancel 业务逻辑。执行这些 Confirm/Cancel 业务时，可能会出现如网络中断的故障而使得全局事务不能完成。因此，故障恢复机制后续仍然会重新提交/回滚这些未完成的全局事务，这样就会再次调用参与该全局事务的各 TCC 服务的 Confirm/Cancel 业务逻辑。

由于 Confirm/Cancel 业务可能会被多次调用，就需要保障其幂等性。
常见方案如下：

1. TCC 事务框架来提供幂等性保障。
2. 业务系统来提供幂等性保障。



### 缺点

- 应用侵入性强：TCC 由于基于在业务层面，至使每个操作都需要有 `try`、`confirm`、`cancel`三个接口。
- 开发难度大：代码开发量很大，要保证数据一致性 `confirm` 和 `cancel` 接口还必须实现幂等性。



# RocketMQ 事务消息实战

了解到事务消息的原理后，我们不难得出一个结论：消息队列集群在整个流程中起着至关重要的作用，如果消息队列集群不可用，所有涉及到分布式事务的业务都将中止！因此，我们需要一个高可用的消息队列集群，能够始终保持在工作状态，即便其某个组件出现故障，也能够在短时间内自动恢复，不会影响业务，还能确保接收到的消息不丢失。

阿里云消息队列 RocketMQ 提供了对于事务消息机制最完整实现，包括半事务消息、确认消息、事务回查机制、消息重试等重要功能。此外，消息队列 RocketMQ 还提供了极强的高可用能力以及数据可靠性，可以确保在各种极端场景下都能提供稳定的服务，并确保消息不丢失。

## 本地事务参与方的业务代码

本文将通过 Java 代码介绍如何实现事务消息相关的业务逻辑，为了简化业务逻辑，我们继续基于 **锁定库存 - > 创建订单** 这个流程来演示，在这个流程中，仅有 2 个事务参与方。

### 1、初始化 TransactionProducer

我们先通过 Maven 引入消息队列 RocketMQ 的 SDK，优先使用阿里云官方提供的 TCP 版 SDK。

```xml
<dependency>
  <groupId>com.aliyun.openservices</groupId>
  <artifactId>ons-client</artifactId>
  <version>1.8.7.2.Final</version>
</dependency>
```

顺利引入 Log4j2 用于日志输出。

```xml
<dependency>
  <groupId>org.slf4j</groupId>
  <artifactId>slf4j-api</artifactId>
  <version>1.7.7</version>
</dependency>
<dependency>
  <groupId>org.apache.logging.log4j</groupId>
  <artifactId>log4j-slf4j-impl</artifactId>
  <version>2.13.1</version>
</dependency>
```



在库存中心的代码中，我们需要初始化一个`TransactionProducer`，用于异步消息的发送，需要填入如下信息：

- Group ID：之前创建的用于本地事务参与方的 Group ID。
- Access key和Secret Key：RAM 用户对应的密钥信息，从 RAM 用户控制台获得。
- Nameserver Address：RocketMQ 实例的接入点信息，从 RocketMQ 控制台获得。

```java
Properties properties = new Properties();
// 您在控制台创建的Group ID。注意：事务消息的Group ID不能与其他类型消息的Group ID共用。
properties.put(PropertyKeyConst.GROUP_ID, "XXX");
// AccessKey ID阿里云身份验证，在阿里云RAM控制台创建。
properties.put(PropertyKeyConst.AccessKey, "XXX");
// AccessKey Secret阿里云身份验证，在阿里云RAM控制台创建。
properties.put(PropertyKeyConst.SecretKey, "XXX");
// 设置TCP接入域名，进入消息队列RocketMQ版控制台的实例详情页面的TCP协议客户端接入点区域查看。
properties.put(PropertyKeyConst.NAMESRV_ADDR, "XXX");
// LocalTransactionCheckerImpl本地事务回查类的实现
TransactionProducer producer = ONSFactory.createTransactionProducer(properties,
    new LocalTransactionCheckerImpl());
producer.start();
```

TransactionProducer 是线程安全的，启动后能在多线程环境中复用。

###  

### 2、获取全局唯一的交易流水号

在发送半事务消息以及执行本地事务之前，我们需要先获取一个全局唯一的交易流水号，订单与交易流水号一一对应，接下来的事务消息机制都会依赖于这个这个交易流水号。我们可以通过引入第三方 ID 生成组件，或者在本地通过 Snowflake 算法实现。



### 3、实现本地事务回查逻辑

创建一个实现了`LocalTransactionChecker`接口的`LocalTransactionCheckerImpl`类，实现其中的`check(Message)`方法，该方法返回本地事务的最终状态。至于具体的业务逻辑如何实现，不在本文讨论的范围之前，我们将其封装在`BusinessService`类中。

```java
package transaction;
import com.aliyun.openservices.ons.api.Message;
import com.aliyun.openservices.ons.api.transaction.LocalTransactionChecker;
import com.aliyun.openservices.ons.api.transaction.TransactionStatus;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
public class LocalTransactionCheckerImpl implements LocalTransactionChecker {
    private static Logger LOGGER = LoggerFactory.getLogger(LocalTransactionCheckerImpl.class);
    private static BusinessService businessService = new BusinessService();
    @Override
    public TransactionStatus check(Message msg) {
        // 从消息体中获得的交易ID
        String transactionKey = msg.getKey();
        TransactionStatus transactionStatus = TransactionStatus.Unknow;
        try {
            boolean isCommit = businessService.checkbusinessService(transactionKey);
            if (isCommit) {
                transactionStatus = TransactionStatus.CommitTransaction;
            } else {
                transactionStatus = TransactionStatus.RollbackTransaction;
            }
        } catch (Exception e) {
            LOGGER.error("Transaction Key:{}", transactionKey, e);
        }
        LOGGER.warn("Transaction Key:{}transactionStatus:{}", transactionKey, transactionStatus.name());
        return transactionStatus;
    }
}
```



### 4、执行本地事务并发送异步消息

我们先组装一条异步消息，其中包含了全局交易 ID，消息将要发往的 Topic，以及消息体。远程事务参与方将通过这个消息体中获取执行远程事务所必须的数据信息。

接下来，将这条异步消息连同一个实现了`LocalTransactionExecuter`接口的匿名类，通过`send`方法进行发送，这就是本地事务参与方所需要实现的所有业务代码了。当然，这个匿名类实现了`TransactionStatus execute.execute()`方法，其中包含了对于本地事务的执行。完整代码如下：

```java
package transaction;
import com.aliyun.openservices.ons.api.Message;
import com.aliyun.openservices.ons.api.ONSFactory;
import com.aliyun.openservices.ons.api.PropertyKeyConst;
import com.aliyun.openservices.ons.api.SendResult;
import com.aliyun.openservices.ons.api.transaction.TransactionProducer;
import com.aliyun.openservices.ons.api.transaction.TransactionStatus;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import java.util.Properties;
import java.util.concurrent.TimeUnit;
public class TransactionProducerClient {
    private static Logger LOGGER = LoggerFactory.getLogger(TransactionProducerClient.class);
    private static final BusinessService businessService = new BusinessService();
    private static final String TOPIC = "create_order";
    private static final TransactionProducer producer = null;
    static {
        Properties properties = new Properties();
        // 您在控制台创建的Group ID。注意：事务消息的Group ID不能与其他类型消息的Group ID共用。
        properties.put(PropertyKeyConst.GROUP_ID, "XXX");
        // AccessKey ID阿里云身份验证，在阿里云RAM控制台创建。
        properties.put(PropertyKeyConst.AccessKey, "XXX");
        // AccessKey Secret阿里云身份验证，在阿里云RAM控制台创建。
        properties.put(PropertyKeyConst.SecretKey, "XXX");
        // 设置TCP接入域名，进入消息队列RocketMQ版控制台的实例详情页面的TCP协议客户端接入点区域查看。
        properties.put(PropertyKeyConst.NAMESRV_ADDR, "XXX");
        // LocalTransactionCheckerImpl本地事务回查类的实现
        TransactionProducer producer = ONSFactory.createTransactionProducer(properties,
                new LocalTransactionCheckerImpl());
        producer.start();
    }
    public static void main(String[] args) throws InterruptedException {
        String transactionKey = getGlobalTransactionKey();
        String messageContent = String.format("lock inventory for: %s", transactionKey);
        Message message = new Message(TOPIC, null, transactionKey, messageContent.getBytes());
        try {
            SendResult sendResult = producer.send(message, (msg, arg) -> {
                // 此处用Lambda表示，实际是实现TransactionStatus execute(final Message msg, final Object arg)方法
                TransactionStatus transactionStatus = TransactionStatus.Unknow;
                try {
                    boolean localTransactionOK = businessService.execbusinessService(transactionKey);
                    if (localTransactionOK) {
                        transactionStatus = TransactionStatus.CommitTransaction;
                    } else {
                        transactionStatus = TransactionStatus.RollbackTransaction;
                    }
                } catch (Exception e) {
                    LOGGER.error("Transaction Key:{}", transactionKey, e);
                }
                LOGGER.warn("Transaction Key:{}", transactionKey);
                return transactionStatus;
            }, null);
            LOGGER.info("send message OK, Transaction Key:{}, result:{}", message.getKey(), sendResult);
        } catch (Exception e) {
            LOGGER.info("send message failed, Transaction Key:{}", message.getKey());
        }
        // demo example防止进程退出
        TimeUnit.MILLISECONDS.sleep(Integer.MAX_VALUE);
    }
    private static String getGlobalTransactionKey() {
        // TODO
        return "";
    }
}
```



得益于 RocketMQ SDK 优秀的封装，发送半事务消息、发送确认消息、事务回查等重要步骤都已经完整实现，不需要开发者再编写代码了，这将为用户带来特别顺畅开发体验。



## **远程事务参与方的业务代码**



相对本地事务参与方而言，远程事务参与方的代码更加简单，只需要从异步消息中提取出对应信息，完成对远程事务的执行即可。

```java
package transaction;
import com.aliyun.openservices.ons.api.Action;
import com.aliyun.openservices.ons.api.Consumer;
import com.aliyun.openservices.ons.api.ONSFactory;
import com.aliyun.openservices.ons.api.PropertyKeyConst;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import java.util.Properties;
public class TransactionConsumerClient {
    private static Logger LOGGER = LoggerFactory.getLogger(TransactionProducerClient.class);
    private static final BusinessService businessService = new BusinessService();
    private static final String TOPIC = "create_order";
    private static final Consumer consumer = null;
    static {
        Properties properties = new Properties();
        // 在控制台创建的Group ID，不同于本地事务参与方使用的Group ID
        properties.put(PropertyKeyConst.GROUP_ID, "XXX");
        // AccessKey ID阿里云身份验证，在阿里云RAM控制台创建。
        properties.put(PropertyKeyConst.AccessKey, "XXX");
        // Accesskey Secret阿里云身份验证，在阿里云服RAM控制台创建。
        properties.put(PropertyKeyConst.SecretKey, "XXX");
        // 设置TCP接入域名，进入控制台的实例详情页面的TCP协议客户端接入点区域查看。
        properties.put(PropertyKeyConst.NAMESRV_ADDR, "XXX");
        Consumer consumer = ONSFactory.createConsumer(properties);
        consumer.start();
    }
    public static void main(String[] args) {
        consumer.subscribe(TOPIC, "*", (message, context) -> {
                    LOGGER.info("Receive: " + message);
                    businessService.doBusiness(message);
                    // 返回CommitMessage，代表给予消息队列集群异步消息已经得到正常处理的回馈
                    return Action.CommitMessage;
                }
        );
    }
}
```



**事务回滚**

是否存在这样的情况：当本地事务执行成功后，因为远程事务没有办法执行，而导致本地事务需要进行回滚操作呢？在事务消息原理分析一节，我们已经介绍过如何通过消息重试，确保远程事务能够执行成功，这是不是已经说明只要异步消息被确认，远程事务就一定可以执行成功，从而不存在对本地事务的回滚呢？

实际生产情况下，确实存在远程事务无法正常执行的情况。比如在付款成功阶段，当本地事务“修改订单状态”执行完成后，在执行远程事务“通知发货”的时，因为订单地址有误而被物流公司拒绝，这种情况下就必须对订单状态进行回退操作，并发起退款流程。

所以在执行远程事务的时候，我们有必要区分如下两种完全不同的异常：

- **技术异常**：远程事务参与方宕机、网络故障、数据库故障等。
- **业务异常**：远程逻辑在业务上无法执行、代码业务逻辑错误等。

简单来讲，当远程事务执行失败的时候，能够通过消息重试的方式解决问题的，属于技术异常；否则，属于业务异常。基于事务消息的分布式事务机制不能实现自动回滚，当业务异常发生的时候，必须通过回退流程确保已经完成的本地事务得到恢复。比如在修改订单状态 -> 通知发货这个场景中，如果由于业务异常导致无法发货的时候，需要通过额外的回退流程，将订单状态设置为“已取消”，并执行退款流程。


![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/qdzZBE73hWtBQcakDwCdKAwhchoKYnQXiatPKveMauibEd5PO82rLLicDDzRtvUNASibmUMtRjL9ialcEbzVk7iafCXA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



在事务消息机制中，回退流程相当于远程事务参与方和本地事务参与方调换了角色，和正常流程一样，同样也可以通过事务消息来完成分布式事务。由于正常流程和回退流程的业务逻辑是完全不一样的，所以最理想的方式是建立另外一个 Topic 来实现。这也就说明，我们在创建事务消息 Topic 的时候，要充分考虑到这个 Topic 背后的业务含义，并**在 Topic 命名上尽可能的与真实业务相匹配**。



## **多个事务参与方**



本节展示的示例中，都只涉及到 2 个事务参与方，但在真实世界中，分布式事务往往涉及到更多的事务参与方，比如之前提到的付款成功环节，有修改订单状态->扣减库存->通知发货->增加积分这 4 个需要同时进行的操作，涉及到 4 个事务参与方。这种情况下如何通过事务消息来实现分布式事务呢？



我们依然可以继续使用之前的架构，只需要加入多个远程事务参与方就行了。可以通过 RocketMQ 的多消费组关联多个远程事务参与方，每一个参与方对应一个 Group ID，在这种情况下，同一个异步消息会复制成多份投递给不同的事务参与方。



![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/qdzZBE73hWtBQcakDwCdKAwhchoKYnQXMfVD2J6qXnicjhkVWYjdOLv03BnptxNSKGPvV9qcxm3jr4zw2zAvj4Q/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)



需要特别引起注意的是，当某个远程事务参与方遇到业务异常的时候，需要**通知其他所有事务参与方执行回退流程**，这无疑会增加业务逻辑的整体复杂度。为了简化事务消息的执行流程，我们可以对业务逻辑预先进行梳理，将子事务分为如下两类：

- 有可能发生业务异常的：比如锁定库存的操作，有可能因为库存不足而执行失败。又比如扣除积分的操作，有可能因为用户积分不足而无法扣除。
- 不太可能发生业务异常的：比如删除购物车条目的操作，除非是技术类故障，一定可以执行成功，即便对应的条目并不存在，也没有关系。又比如积分增加的操作，只要对应的用户没有注销，是不可能遇到业务异常的。



我们尽量将第一类事务作为本地事务而实现，将第二类事务作为远程事务而实现，这样就可以最大程度避免回退流程。



![图片](https://mmbiz.qpic.cn/sz_mmbiz_png/qdzZBE73hWtBQcakDwCdKAwhchoKYnQXsP35Vu7DHCVh0VeN976OgdBJDuX5w2Zf7IAq2j7DgWjm1MjhlRffyQ/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1)







## 其他注意事项

### **消息幂等**

RocketMQ 能保证消息不丢失，但不能保证消息不重复，所以消费者在接收到消息后，有必要根据业务上的唯一 Key 对消息做幂等处理。在抢购业务中，唯一 Key 当然就是全局唯一的交易流水号，具体幂等处理方法在互联网上有很多文章供读者参考。

当然，不是每一种业务远程事务都需要确保消息的幂等性，比如删除购物车指定条目这样的操作，在业务上是可以容忍多次反复执行的，就没有必要引入额外的幂等处理了。



### **每日对账**

不同于传统事务的强一致性保证，柔性事务需要经历一个中间状态，才到达成事务的最终一致性。有某些特殊情况下，这个中间状态会持续非常长的时间，甚至需要人工主动介入才能实现最终一致性：

1、消息重试多次后，依然不成功：当消费者完全无法正常工作的时候，RocketMQ 不可能永无止境地重试消息，事实上，如果16次重试后异步消息依然没有办法被正常处理，RocketMQ 会停止尝试，将消息放到一个特殊的队列中。

2、未处理的业务异常：比如给某个账号加积分的时候，发现此账号被注销了，这是一个非常罕见的业务现象，有可能事先对此并没有健壮的处理机制。

3、幂等校验失败：处理幂等所依赖的系统比如 Redis 发生了故障，导致某些消息被重复处理。

4、其他严重的系统故障：比如网络长时间中断，留下了大量执行到一半的事务。

5、其他漏网之鱼。



这些情况下，我们都有需要通过定期对账机制来进行排查，在必要的时候发起人工主动介入流程，修复不一致的数据。事实上，在任何柔性事务的实现中，每日对账都是必不可少的数据安全保障性手段。
