# Spring

1. IOC 容器初始化可以总结为以下步骤：

   1. 初始化的入口在容器实现中的 refresh() 调用来完成。
   2. 使用 ResourceLoader 对 Bean 配置进行定位（容器本身就继承了 ResourceLoader 的默认实现DefaultResourceLoader），并加载配置资源 Resource。
   3. 使用 BeanDefinitionReader （如 xml 使用 XmlBeanDefinitionReader，注解使用 AnnotatedBeanDefinitionReader）将上一步加载的 Resource 解析成 BeanDefinition（Spring Bean 的定义） 并注册到 IOC 容器中（容器持有 BeanFactory 的默认实现类 DefaultListableBeanFactory），实际上就是使用一个 HashMap 去存储 BeanName 和对应的 BeanDefinition。
   4. 容器本身就是一个 BeanFactory，其定义了对 Bean 的获取等操作接口，最终调用的是容器本身持有的 BeanFactory 的子类 DefaultListableBeanFactory 的方法实现。




2. 实例化和注入
   1. 对于不是懒加载且 Singleton 模式的 Bean 会在初始化时实例化，而如果是懒加载（默认）的 Bean 则在 getBean() 时才会实例化 Bean。
   2. getBean() 作为实例化入口，首先会在 IOC 容器缓存中获取，没有则往父级容器缓存中尝试获取。
   3. 如果缓存都没有则实例化 Bean，实例化前先对依赖的（dependsOn）Bean 实例化，即对其调用 getBean()方法。若有循环依赖则会报错。
   4. 根据创建模式，如 singleton、prototype等创建其实例，实际调用AbstractAutowireCapableBeanFactory.createBeanInstance() 实例化对象。
   5. 根据不同的初始化策略实例化 Bean 对象。
   6. 使用 JDK 的反射方法或者 CGLib方式实例化对象。
   7. 创建后的实例对象（Singleton 模式）先将引用缓存到 IOC 容器中。
   8. 根据属性类型进行值转换。
   9. 根据属性类型进行值注入。



3. AOP

   1. 根据 AOP 配置判断是否有 Advisor 符合 Bean，如果有就选择对应的策略（JDK 动态代理/CGLib 动态代理）创建代理对象。
   2. 调用代理对象方法时，获得该方法的拦截器链，通过拦截器链触发通知执行。

4. Spring MVC

   1. Spring MVC 自带 Web 容器，程序员开发时不需要单独将工程部署到 Web 容器上，直接运行 Spring MVC 项目即可运行 Web 服务。
   2. Spring MVC 对 Web 架构进行分层模型，主要分为三层：Controller 层（用于定义 Web 服务接口，即常见的一个 url 对应一个接口方法），Service 层（具体的业务逻辑），DAO 层（操作数据库）。
   3. Spring MVC 提供核心类 DispatcherServlet，其实现 HttpServlet。开发时只需在配置该 DispatcherServlet 的具体实现类即可。客户端访问时，会由底层的 Web 容器封装对应的 Request/Response 传到 DispatcherServlet，并由 DispatcherServlet 作为调度器调度一系列组件进行处理。
   4. DispatcherServlet 首先调度 HandlerMapping，找到请求 url 对应的执行链（handler 和 interceptor）。
   5. DispatcherServlet 将第四步获得的执行链交给 HandlerAdapter 进行处理，HandlerAdapter 将请求数据适配转换成方法所需参数，并调用方法。
   6. DispatcherServlet 将方法处理完后会返回视图数据交给对应的 ViewResolver  解析成 View，最终通过 View 进行视图数据渲染返回给客户端。

5. jdk 和 cglib动态代理

   aop实现原理，以及jdk动态代理会遇到的问题？
   在spring中会有两种方式实现动态代理。
   分别是jdk提供的和cglib，spring默认使用jdk实现，但是jdk是基于接口实现，动态代理的方法需要在接口中定义。因此会存在问题:如果代理类没有接口实现，就不能进行动态代理。
   那cglib就没有什么问题了吗？
   而cglib是基于继承的形式，动态生成代理类的子类字节码文件。因此存在问题:如果类是final就不能使用cglib
   因此我们一般推荐面向接口编程



6. PrepareStatement 好处

   1. 批量操作时可以利用 PrepareStatement 的预编译特性，从而避免多次编译，导致执行效率慢。
   2. 参数占位符，提供占位符的机制，避免编写多次重复语句。
   3. 防止 SQL 注入。因为参数是作为 String 解析，而不会经历编译阶段。

7. jdbc

   使用传统的 JDBC 编写数据库操作时需要以下步骤：

   1. 加载驱动程序
   2. 获得数据库连接
   3. 操作数据库，实现增删改查
   4. 获取结果集并遍历结果
   5. 关闭ResultSet、Statement、Connection资源

   当然使用数据库连接池可以节省为：

   1. 从 DataSource 获取连接
   2. 操作数据库，实现增删改查
   3. 获取结果集并遍历结果

# 网络

2. http1.0 1.1 2.0区别

3. http https区别

4. 怎么实现长连接

5. 长连接用的什么字段

6. http报文包含什么

7. http有哪些状态码

8. tcp三次握手

9. tcp的拥塞控制

10. tcp有什么缺点

11. 提高传输速率还有什么解决办法

12. udp如果要实现可靠怎么办

13. http请求有哪几种

14. OSI七层

    1. 应用层：为特定应用程序提供数据传输服务，例如 HTTP、DNS 等。数据单位为报文。
    2. 表示层：数据压缩、加密以及数据描述。这使得应用程序不必担心在各台主机中表示/存储的内部格式不同的问题。
    3. 会话层：建立及管理会话。

    > 由于表示层和会话层一般交给程序开发去定义具体的实现，因此也可以归结为应用层内容。

    4. 运输层：提供的是进程间的通用数据传输服务。由于应用层协议很多，定义通用的运输层协议就可以支持不断增多的应用层协议。运输层包括两种协议：传输控制协议 TCP，提供面向连接、可靠的数据传输服务，数据单位为报文段；用户数据报协议 UDP，提供无连接、尽最大努力的数据传输服务，数据单位为用户数据报。TCP 主要提供完整性服务，UDP 主要提供及时性服务。
    5. 网络层：为主机之间提供数据传输服务，而运输层协议是为主机中的进程提供服务。网络层把运输层传递下来的报文段或者用户数据报封装成分组。
    6. 数据链路层：网络层针对的还是主机之间的数据传输服务，而主机之间可以有很多链路，链路层协议就是为同一链路的结点提供服务。数据链路层把网络层传来的分组封装成帧。
    7. 物理层：考虑的是怎样在传输媒体上传输数据比特流，而不是指具体的传输媒体。物理层的作用是尽可能屏蔽传输媒体和通信手段的差异，使数据链路层感觉不到这些差异。

15. 应用层还有啥协议

16. cookie和session区别
    首先说一下这两个是什么？
    我们对于一次web访问，会建立一次链接，在服务端对应的会生成一个session(会话)，因此本次会话的数据会存放在这个session中。会话结束，该session对象就会被销毁。
    而cookie是存在浏览器的用来存放数据，为什么有了session还需要cookie，因为我们会话结束后，session数据就会丢失，因此如果数据需要在多次会话就需要存放在客户端。
    Cookie缺点:不安全，因为存放在客户端可能被盗用。存储大小有限，限4k。客户端可能禁止cookie(禁止则需要将参数通过url传输)。cookie一般用来存储登陆token信息，这样只要登陆一次就不用每次访问都重新登陆

# 多线程

1. **进程和线程区别**

   1. 进程是一个运行的程序，是系统资源分配和调度的单位。
   2. 一个进程可以有多个线程，线程是进程中最小的执行单位。

   3. 线程可以共享进程的共享资源和空间地址。

   4. 线程上下文切换时，只需记录当前运行到哪一行代码，进程则需要保存当前CPU环境，和新被调度运行进程的CPU环境设置。

   

2. **实现多线程的方法**

   1. 直接创建 Thread 类对象。通过构造参数传入线程要执行的任务（实现 Runnable 接口）
   2. 继承 Thread 类。实际上 Thread 类实现了 Runnable 接口，因此可以继承 Thread 类并复写 run 方法。
   3. 线程池

3. **线程的生命周期**

   ![线程生命周期](C:\Users\63190\Desktop\pics\线程生命周期.png)

   wait、sleep、yield方法的区别：

   * wait：调用 wait 的线程会释放锁资源和CPU资源。线程会被阻塞直到被 notify/notifyAll 唤醒。
   * sleep：调用 sleep 的线程会释放CPU资源，但不会释放锁资源。线程会被阻塞，直到时间超时。
   * yield：调用 yield 的线程会释放CPU资源，但不会释放锁资源。线程不会被阻塞，当下一次获得 CPU 资源时可继续执行。

4. **synchronized 和 lock的区别**

   1. Synchronized 是 Java 提供的一种内置锁，其基于 jvm 层面实现。Lock 是接口，其封装了锁，是 Java 类。
   2. Synchronized 无法判断其锁对象是否已经被获取。Lock 可以判断是否已有线程获取到锁（isLocked() 方法）。
   3. Synchronized 当同步代码块执行完、发生异常、显示控制（wait/notify/notifyAll） 才会将锁资源释放。Lock  可以手动在适当的位置调用 unlock() 方法释放锁。
   4. 获取 Synchronized 锁的线程会一直尝试去获取，如果获取不了就会阻塞等待。 Lock 锁提供 tryLock()，可以尝试获取锁，如果尝试获取不到锁就会直接返回，不会阻塞等待锁。
   5. Synchronized 锁可重入、不可中断、非公平，而 Lock 锁可重入、可判断、可公平（两者皆可）。
   6. Lock 锁适合大量同步的代码的同步问题，synchronized 锁适合代码少量的同步问题。

   

5. **死锁的条件**

   1. 资源不能被剥夺，分配的资源在未使用完成前不能前行被剥夺
   2. 互斥条件，一个资源只能被一个线程使用
   3. 请求和等待条件，线程请求其他资源而阻塞时，对持有的资源不放
   4. 循环等待，若干个线程互相阻塞，并等待对方释放持有的资源，从而造成环状。

6. **悲观锁和乐观锁**

   悲观锁：不管实际是否出现多线程并发修改共享资源，先获取锁，以确保只有获取到锁的线程才能执行同步代码块操作，保证了串行执行代码。

   乐观锁：乐观锁实际是一种无锁的概念，通过 CAS 尝试去修改共享资源 + 失败重试的机制，来确保对共享资源的操作最终能修改成功。

   乐观锁和悲观锁的区别在于：

   * 悲观锁同一时刻只能一个线程获取到锁资源然后执行操作，其他线程会被阻塞。而乐观锁为了避免线程阻塞挂起所带来的的消耗，而采取 CAS + 失败重试来实现。
   * 当锁资源很快就被释放时，乐观锁会比悲观锁性能更好，但如果锁资源长时间不被释放，那么乐观锁的失败重试机制反而会造成 CPU 资源浪费，因此一般对失败重试增加有限的次数，避免一直轮询重试。

7. **cas 是什么**

   CAS —— compareAndSwap 比较和替换。

   通过 CAS 类封装共享资源，从而保证了共享资源单个操作的原子性。

   其原理是比较用户提供的预期值和内存中的值（避免了缓存），如果相同则替换成用户定义的更新值并返回成功，如果不同则返回失败。该操作由 JVM 底层保证原子性。

   

8. **synchronized的jdk1.8优化**

   * 偏向锁：单个线程竞争锁资源，其实际上不会加锁
   * 轻量级锁：实际上是个自旋锁，CAS 的方式尝试获取锁资源。
   * 重量级锁：竞争激烈，升级为重量级锁，其他线程只能阻塞等待锁资源

9. **volatile**

   Java 通过 volatile 关键字解决可见性问题。Java 编译器会对 volatile 字段的读写前后插入内存屏障。（实际会生成一个 Lock 的汇编指令，根据不同的底层替换成对应的 CPU 指令）



# 基础

1. 集合类型

   1. list、set、queue、map

2. hashmap的数据结构

   1. 数组+链表

3. 1.7和1.8的hashmap有什么区别

   hashmap 会有一个数组，数组每个下标称为桶，桶用于存储节点。

   jdk 7 时该节点叫 entry，jdk 8 时改为 node，实际上是相同的。

   jdk 7 时每个节点实际上是一个链表节点，每个节点会有一个指针指向下一个相同hash的节点，从而形成链表。jdk1.8之后当链表节点数量大于8时会将链表变成红黑树结构。

   

4. hashmap怎么解决hash冲突

   1. 扩容机制，降低hash冲突
   2. 冲突时，jdk1.7是链表，每个节点实际上会有一个指针指向下一个相同hash的节点，从而形成链表。jdk1.8之后当链表数量大于8时会将链表变成红黑树结构。

   

5. hashmap长度为什么是2的次方

   因为我们要确定桶的位置，所以需要将hashcode的值和桶的大小取模得到key具体落在那个桶。

   而取模的操作实际上在底层中是要换算成位运算的，因此hashmap直接使用位运算提高运算效率。

   当 x为2的次方时，一个数和x-1作与运算等价于取模，所以才要求hashmap的长度为2的次方。如果不是2的次方，默认会改成2的次方。

   

6. hashmap的扩容机制，扩容因子是多少，为什么这样设置

   1. 当hashmap的桶使用个数大于桶的大小*扩容因子时，会进行扩容。因为为了避免hash冲突，所以把数组的大小进行扩容。
   2. 首先会分配一个原来两倍大小的table，然后将旧的table所有键值重新rehash插入到新的table中。

   

7. hashcode怎么计算

   通过将key的hashcode高16位与低16位进行异或运算。

   

8. hashmap怎么找到对象的位置

   1. 首先通过key计算 hashcode，并根据 hashcode 取模 hashmap 大小得到数组具体下标（即桶）。
   2. 如果桶没有元素，则对象不存在，。
   3. 如果桶有元素判断链表或者红黑树的节点key和hashcode是否和查询的对象一直。

   

9. hashmap的树化的条件，为什么这样设置

   1. 当链表节点数量大于8时就会转成红黑树。
   2. 因为链表长度越大，则查询效率越慢，因为链表是顺序查询。因此为了提高查询速率将链表转换成红黑树。

10. hashmap的线程安全问题

    1. 多个线程同时put操作，新插入的头节点可能会被后插入的覆盖。而不是插入两个节点。
    2. 多个线程同时remove操作，移除同一个下标的节点，原本应该移除多次，但可能由于并发，使得移除的实际为同一个节点。
    3. 多个线程触发 resize() 操作，resize() 操作实际上是从链表头开始依次遍历插入到新的数组中，知道节点的next为null就意味着遍历完了，该链表全部挪到了新的数组中。但多线程进行 resize() 时，当一个线程还没对最后一个节点（next为null）插入到新的数组时，此时切换到另一个线程执行 resize()，此时扩容完成后，原本最后一个节点会变成头节点，并且next不为null。此时切换回原线程继续执行，就会导致原来的链表最后一个节点的next不为null，从而导致ABA问题，即B节点指向A节点，但由于上述问题导致B节点的next不为null，而是A，从而又将A节点作为头节点又插入到新的数组中，形成ABA。

    

11. hashmap怎么实现线程安全

    1. 对于hashmap更新的操作，可以同一在外部通过同步的方式访问， 避免多个线程同时修改hashmap。
    2. 使用 JDK 同步包下提供的 ConcurrentHashMap 同步容器。

    

12. hashmap的put操作

    1. 计算出key的hash，落在哪一个桶
    2. 判断数组是否需要初始化
    3. 如果桶的位置为空，那么直接创建节点放到桶中。然后判断是否需要扩容，返回null。
    4. 如果桶的位置不为空
       1. 如果是红黑树则会写入新的节点。
       2. 如果是链表，则会遍历链表，如果以前没有插入过则写入新的节点并判断是否要转成红黑树，反之则返回以前插入过的节点。
    5. 对节点（可能是以前已有的，也可能是新插入的）进行值的修改，然后返回。

    

13. 为什么[红黑树](https://www.nowcoder.com/jump/super-jump/word?word=红黑树)而不是其他树

14. 1.7和1.8的concurrenthashmap有什么区别

    JDK 1.7 分段锁机制来实现并发更新操作，核心类为 Segment，它继承自重入锁 ReentrantLock。

    JDK 1.8 的实现不是用了 Segment，Segment 属于重入锁 ReentrantLock。而是使用了内置锁 synchronized，主要是出于以下考虑：

    1. synchronized 的锁粒度更低；
    2. synchronized 优化空间更大；
    3. 在大量数据操作的情况下，ReentrantLock 会开销更多的内存。

    并且 JDK 1.8 的实现也在链表过长时会转换为红黑树。

15. get操作的时候会加锁吗

16. 不加锁怎么保证线程安全

17. concurrenthashmap扩容原理



1. arraylist和 linkedlist 的区别

   arrayList：基于动态数组实现。

   * 查询快，由于通过数组实现，因此可以通过下标直接访问元素。
   * 删除插入慢，因为删除插入会将对应的index后面的元素进行挪动（System.arrayCopy() 进行复制）
   * 扩容慢，因为扩容需要重新分配一个数组（原数组1.5倍），然后进行复制。

   linkedlist：基于双向链表实现。

   * 查询慢，由于链表内存空间不连续，需要顺序遍历每个节点。
   * 插入删除快，由于链表不需要进行将元素进行挪动，只需要对应index前后节点的指针即可。
   * 可以通过linkedlist实现栈、队列、双端队列。
   * 扩容快，因为不需要连续的内存空间。

   

2. 什么时候用arraylist 什么时候用linkedlist

   1. 一般情况都使用 arraylist，因为 arraylist 查询速度快。当然在使用前要预先估计 arraylist 的大小，从而避免扩容带来的耗时。而且也要注意 arraylist 需要连续的内存空间。
   2. 在需要实现栈、队列、双端队列情境下，可以考虑使用 linkedlist。

   

3. hashtable和hashmap的区别

   1. HashTable 是同步的，它使用了 synchronized 来进行同步（所有方法都加锁，意味着同一时间只能有一个线程访问）。它也是线程安全的，多个线程可以共享同一个 HashTable。HashMap 不是同步的，但是可以使用 ConcurrentHashMap，它是 HashTable 的替代，而且比 HashTable 可扩展性更好。

   2. HashMap 可以插入键为 null 的 Entry。

   3. HashMap 的迭代器是 fail-fast 迭代器，而 Hashtable 的 enumerator 迭代器不是 fail-fast 的。

   4. 由于 Hashtable 是线程安全的也是 synchronized，所以在单线程环境下它比 HashMap 要慢。

      

4. equals和== 区别

   1. ==：如果是基本数据类型，则比较的是值。如果是引用类型，则比较的是引用地址。
   2. equals：比较的是两个对象是否等价。

   

5. ClassNotFoundException 和 NoClassDefError区别

   ClassNotFoundException 是编译前就会检查出来的错误，找不到指定的 Class，无法编译。

   NoClassDefError 是运行时的错误，编译时该类是存在的，但可能由于以下原因导致运行时类不存在：

   1. 加载该类时发现找不到该类的.class文件或者该类的jar包不存在；
   2. 类的.class文件存在，但是在不同的域中。比如说.class文件在当前的java path下不可用又或者说有多个不同的类加载器重复对该类的.class文件进行了加载，就有可能出现这样的问题。
   3. 大小写问题。如果类名大小写不同，但字母都一样，在编译时只会生成一个全小写的class文件。因此在实际运行时，想加载大写class，但由于只有小写的class文件，则会导致该错误。

   

6. Vector 是否线程安全

   Vector 单个操作的时候确实是线程安全（因为加了 Synchronized），但在复合操作时就不能保证。如 Iterator 遍历时同时修改 Vector，则会抛出 ConcurrentModifyException，因为遍历和修改操作是复合操作。

7. List遍历线程安全

   遍历方式可以分为三种：

   1. for 循环，通过指针遍历
   2. Iterator 迭代器遍历。
   3. foreach 遍历，Java 8提供的Lambda

   前两种在并发情况下（遍历+修改的复合操作），会导致

# JVM

1. 类加载的过程

   1. 装载，通过ClassLoader 对类文件的装载。（使用双亲委派机制）
   2. 链接，主要分为验证（验证文件是否为 class、字节码等信息）、准备（为静态变量分配内存，并进行默认初始化）、解析（将类中的符号引用转换成直接引用，即将引用类的地址替换掉符号引用）
   3. 初始化，对静态变量初始化为用户定义值。

   

2. 双亲委派机制

   1. 类是通过全路径名的区分的，因此同一路径下不能有相同的类。
   2. JVM 有多个ClassLoader，区别在每个 ClassLoader 会加载指定的路径下的类文件，为了避免重复加载同一路径下的类文件，子类 ClassLoader 加载类文件时会先询问父类ClassLoader 是否能加载，如果不能才由自己尝试加载，从而避免了重复加载。

   

3. jvm的内存区域

   1. JVM 内存区域主要分为两个部分：堆和非堆（方法区）
   2. 堆是存储对象实例和数组。方法区是存储类信息、常量池、静态变量、即时编译器生成的数据。
   3. JDK 8 后常量池和静态变量挪到了堆中。

   

4. gc有几种垃圾清理算法

   1. 标记清理法，先标记存活的对象，再清除。

   2. 复制算法，将标记存活的对象复制到另一个内存空间，保证有一个空间是空的，另一个空间的对象整齐存放。

   3. 标记整理法，先标记存活的对象，再将存活的对象压缩到一边，将边界以外的内存清空。

      

5. gc为什么要分代

   1. 通过分代区分不同的对象，并根据每个代的特性选择对应对应的回收算法。堆内存分为新生代和老年代。新创建的对象会在新生代中分配内存，由于新创建的对象80%都会在第一次gc后被回收，因此新生代使用复制回收算法。当对象达到一定的年龄（经历多少次gc都存活）就会被移到老年代存储，老年代gc后，绝大多数对象都还是会存活，因此老年代适合使用标记整理回收算法。

      注意：大对象的创建也会直接存储到老年代。

      

6. G1收集器

   1. g1 收集器使用的是标记整理回收算法。
   2. 对于新生代、老年代不在按照物理隔离，而是将整个堆划分成多个 region 区，每个 region 区都可以成为 eden 区、survivor 区、old 区、h 区。
   3. G1通过优先列表计算各个region里面的垃圾堆积价值（回收获得的空间以及回收所需时间），每次根据允许的收集时间（用户设置），优先回收价值最大的Region（Garbage-First名称的来由）。通过充分利用硬件优势（多CPU、多核）及优先回收的特性尽可能满足用户定义的收集时间（停顿时间），从而使用户线程有更多的时间执行

   

7. G1和CMS的区别

   1. 两者同样是执行过长大致相同，都是初始标记（STW）、并发标记、重新标记（STW）、回收
   2. CMS 作用在老年代、G1是整个内存空间
   3. cms采用的是标记清理、g1整体上采用的是标记整理，具体采用的是复制算法
   4. g1是垃圾优先算法，在满足用户预期的停止时间基础上，尽可能回收垃圾更多的region区。




# 数据库

1. **索引的数据结构是什么**

   MySQL中索引有两种数据结构，B+ Tree 和 Hash，而 InnoDB 存储引擎使用的是 B+ Tree。

   

2. **b+树的特点**

   1. B 树有的都有（如节点根据关键字数量变化而进行分裂或合并）
   2. 每个节点的关键字数和路数（子节点）是相同。
   3. 叶子节点才会存储数据。
   4. 叶子节点通过一个指针指向相邻节点，从而形成链表，有利于范围查询
   5. 左闭右开的区间去检索数据。

   

3. **b+树为什么数据都放在叶子节点**

   实际就是 B+ tree 好处。

   1. 由于每访问一层代表一次IO磁盘访问，为了减少层数，减少IO磁盘访问次数，因此将数据都放在叶子节点，非叶子节点存储索引+指针。

      理论上如果索引bint+指针只需14字节，一条数据1kb，我们知道一个节点16k，那么三层就能存储`1170*1170*16=21902400`条数据。

      而且由于访问索引中每一条数据，IO 磁盘访问次数是一致的，一般最多三次就够了，保证了查询速率的稳定。

   2. 叶子节点通过指针指向相邻的节点（有序链表），因此对于范围查询，只需要获取第一个数据，然后顺序遍历链表即可。

   

4. **磁盘IO为什么少，如果没命中数据呢，不也要磁盘io多吗**

   1. 首先使用索引避免了全表扫描。
   2. 由于 b+ tree的特点，检索2000w+数据只需三次 IO 磁盘访问即可。

   

5. **Mysql 数据库有哪些存储引擎**

   最常用的是 MyISAM 和 InnoDB，然后还有 Memory、CVS、Archive。

   

6. **InnoDB 和 MyISAM 的区别**

   1. MyISAM 是5.5版本前默认的存储引擎，InnoDB 是5.5版本后默认的存储引擎
   2. InnoDB 支持事务（因为支持 XA 协议和 SavePoints（嵌套事务）），因此 InnoDB 适合业务数据一致性要求高的场景
   3. InnoDB 支持行级别的锁，MyISAM 支持表级别的锁。因此 InnoDB 适合高并发更新场景（锁粒度小），MyISAM 适合读操作为主的场景。
   4. InnoDB 存储会对每张表生成两个文件（存储结构frm、索引和数据ibd），MyISAM 存储会有三个文件（存储结构frm、索引myi、数据myd），InnoDB 索引和数据是存放在一起，MyISAM 则是分开存储。
   5. MyISAM 索引（主键索引或辅助索引）的叶子节点存的是另一个数据文件中数据对应的磁盘地址，InnDB 主键索引（聚集索引）存的是数据，而辅助索引（非聚集索引）存的是主键值（通过主键值再从主键索引查找数据）

   

7. **innodb的索引怎么实现的**

   InnDB 主键索引（聚集索引）存的是数据，而辅助索引（非聚集索引）存的是主键值（通过主键值再从主键索引查找数据）

   

8. **聚簇索引和非聚簇索引的区别**

   聚集索引（聚簇索引）索引键值的逻辑顺序跟表数据行的物理存储顺序是一致的。因此主键索引是聚集索引，非主键索引（辅助索引）为非聚集索引。

   

9. **哪些是非聚簇索引**

   非主键索引（辅助索引）为非聚集索引。

   

10. **什么时候用到唯一索引**

    1. 索引是为了提高查询效率，因此索引列不能频繁更新。
    2. 唯一索引的列不能有重复值，可以有null值。
    3. where 查询中使用到索引字段。

    

11. **联合索引什么时候用到**

    1. 查询判断条件有多个字段，可以对该多个字段建立联合索引，前提是索引值（从而避免建立多个单列索引）

    2. 使用时要符合最左匹配。

       

12. **什么是最左前缀原则**

    1. 使用联合索引要符合最左匹配原则，即（a,b,c）联合索引，实际上等同于 (a)，(a,b)，(a,b,c)三个索引，因此查询时用到的判不能不用第一个字段，不能中断。

    

13. **innodb 中存储2000w个数据，b+ tree 要多少层，计算公式是什么**

    三层，如果索引bint+指针只需14字节，一条数据1kb，我们知道一个节点16k，那么三层就能存储`1170*1170*16=21902400`条数据。

    

14. **事务 acid**

    1. a：atomicity 原子性，事务中的操作要么全部提交成功，要么失败全部回滚。通过 undo log实现，undo log 记录事务中数据修改前的值，一旦失败回滚，就可以通过 undo log 对修改过的数据进行回滚。
    2. c：consisitency 一致性，事务执行前后数据整体上保持一致性，如主键还是唯一的，字段长度要符合，业务上逻辑上是一致的。
    3. i：isolation 隔离性，多个事务同时对同一张表或同一行数据进行操作互不干扰，从而保证数据的一致性。
    4. d：duration 持久性，事务一旦提交，那么事务对应的操作就必定会持久化到磁盘，不会因宕机或重启而导致数据丢失。通过 redo log + double write来保证。redo log 保证数据页的操作一定会执行，double write 保证数据页完整性，保证 redo log恢复时数据页是完整可用的。

    

15. **什么是幻读**

    幻读指其他事务对表插入新的数据，导致事务执行过程中，前后两次查询的数据量不一致。

    

16. **隔离级别有哪些**

    为了解决不同的读一致性问题，数据库划分了四个隔离级别，并且定义每个隔离级别不同程度解决那些读一致性问题，由厂商为具体的隔离级别提供实现：

    1. 未提交读（Read Uncommitted）：事务可以读取其他事务未提交的数据，因此会出现脏读。

    2. 已提交读（read Committed）：事务可以读取其他事务已提交的数据，不可读取其他事务未提交的数据，从而解决了脏读，但会出现不可重复读。

    3. 可重复读（Repeatable Read）：事务执行过程中多次读取同一数据，其数据结果为一致，但没有解决幻读。InnoDB 可以在该隔离级别解决幻读。

    4. 串行化（Serializable）：事务将存放在队列中依次执行，因此不存在并发情况，也就不存在读一致性问题。

       

17. **如何实现可重复读**

    1. InnoDB 通过mvcc 可重复读。
    2. mvcc 通过快照的方式，使得事务内多次读一致，因为读取的是快照的数据。

    

18. **mvcc知道吗，作用**

    1. InnoDB通过 mvcc 实现可重复读事务隔离级别，每个事务开启时，生成一个快照，事务读取数据会从自己的快照读取，从而实现事务内多次读取数据一致。

    

19. **多个线程访问一个数据，怎么保证线程安全**

    实际是事务隔离级别。

    1. 如果多个线程都只是读取数据，那么本身就是线程安全的。但如果涉及读和写则需要一定的机制保证一定的安全。
    2. RC 级别，通过 MVCC 可以解决事务内可重复读，但无法处理事务外的幻读（其他事务插入了数据，导致本事务中读取的数据数量和实际数据数量不一致）
    3. RR 级别，除了 MVCC 解决了事务内可重复读，还提供了间隙锁，使得事务内通过加锁的方式，可以避免其他事务插入数据导致幻读。
    4. Serializable 级别，事务内所有读写操作都加锁，其他事务无法进行修改。

    

20. **除了间隙锁还有什么锁**

    1. 记录锁——锁住单条记录
    2. 临键锁——记录锁+间隙锁

    

21. **事务如果对多个数据库进行操作，怎么实现**

    1. 强一致性，通过协调者（Mycat、Sharding-JDBC等）调用多个数据库的XA接口，控制多个事务的提交或回滚（2pc或者3pc）。
    2. 消息队列，通过失败重试、补偿、预警等机制使得最终一致性，从而避免事务。

    

22. **数据库查询很慢，有什么优化方法**

    1. 首先要定位，慢在哪里。
    2. 大量连接处理。可以考虑客户端使用连接池；服务端进行扩展（如主从模式、或者按照服务拆分数据库）最终目的都是让大量的请求落到不同的数据库节点。
    3. 滚。y。据，不会经常改动的数据，可以考虑加一层缓存层，如Mybatis的缓存（单节点的），更多的是独立缓存服务Redis缓存。
    4. 存储引擎。如以读为主的可以使用 MyISAM，写为主的用 InnoDB。
    5. 语句问题。通过慢SQL查询定位到那些语句慢，然后对语句进行 Explain 分析执行计划。
       1. 语句本身有问题，如有无谓的操作——优化语句本身，全查询——加 limit 分页。
       2. 没有用到索引，建立使用索引。
       3. 数据量大等，一般单表500w建议可以分表，如订单表，可以按照月份分表。
       4. 锁的竞争，
    6. 网络问题。客户端和数据库不在同一个网络，可能会有网络延迟。

    

23. **什么是 Redo log**

    redo log 是一种物理日志，记录的是对物理数据页操作。通过先记录日志，再执行写磁盘，从而保证：

    1. 事务持久化保证：宕机导致内存修改数据没有写入到磁盘中，也能通过启动时加载 redo log 重新对物理数据页操作。

    2. 操作写到一半，宕机，导致数据页不可用，数据失效，也能通过 redo log + 双写缓冲对数据页进行恢复然后再对物理数据页操作

       

24. **什么是 undo log**

    undo log 是事务回滚日志，记录的是逻辑日志（数据在事务之前的状态），redo log 记录前会先将数据状态记录在 undo log，如果事务回滚，则通过该日志直接将数据回滚到事务开启前状态。

    

25. **什么是 binlog**

    事务提交时，会将事务中的更新语句记录在binlog，可以用于数据恢复或者主从复制。

    

26. **索引失效**

    1. 有or必全有索引;
    2. 复合索引未用左列字段;
    3. like以%开头;
    4. 需要类型转换;
    5. where中索引列有运算;
    6. where中索引列使用了函数;
    7. 如果mysql觉得全表扫描更快时（数据少）;

# Redis

1. **Redis中SDS是什么**

   在 Redis 中通过 SDS 封装字符串，SDS 包含了字符串长度、数组分配大小、SDS类型、字符数组（存储）

   和传统字符数组实现有以下优点：

   1. 不用关注内存溢出问题，提供了扩容机制。
   2. 通过字符串长度属性来判断字符数组结束，而不用判断结束符，从而避免了二进制内容结束符误判问题。
   3. 快速获取字符串长度，不用遍历数组内容。
   4. 通过空间预分配（分配足够的空间）和惰性释放（长度变小不会立刻缩容）机制，避免了频繁扩容/缩容。

   

2. **redis支持哪些数据结构**

   String、Hash、Set、Sort Set、List、bitmap、GEO、Hyperloglogs

   

3. **set的数据结构**

   k/v数据结构，外层是 hashtable（字典），索引到key对应的value（dictEntry），而dictEntry 的redisObject为有两种：

   1. 元素个数少于 512 个通过 inset 存储
   2. 反之则用 Hashtable，key为元素值，val为null

   

4. **string数据结构**

   1. k/v数据结构，外层是 hashtable（字典），索引到key对应的value（dictEntry），而dictEntry 的redisObject为有三种：
      1. int：存储 8 个字节的长整型（long，2^63-1）。
      2. embstr：代表 embstr 格式的 SDS，存储小于44 个字节的字符串。
      3. raw：代表 raw 格式的 SDS，存储大于44 个字节的字符串。

   

5. **redis是单线程的还是多线程的**

   redis 是单线程的。

   

6. **单线程为什么效率这么高**

   1. 基于内存的存储数据，从而避免磁盘 I/O 操作耗时。
   2. 多路复用机制，通过单线程可以同时接收多个请求。
   3. 由于单线程，从而避免线程创建和销毁以及上下文切换和资源竞争问题。
   4. 数据操作简单，没有关联查询等复杂操作。

   

7. **redis怎么保证缓存和数据库数据的一致性**

   强一致性：先删除缓存-》更新数据库-》再删除缓存

   第一次删除是让缓存不可用。

   第二次删除是防止更新数据库前其他客户端访问了数据库导致缓存了旧的值。

   删除操作通过消息队列确保一定成功

   如果可以接受最终一致性：更新数据库 -》 更新缓存（缓存要设置过期时间或者定期更新缓存，从而确保缓存最终一致性）

   

8. **Redis Cluster 如何批量操作**

   对于 multi key 操作是不能落在同一个节点上处理的，因为每个 key 都有可能映射不同的 slot。为了让多个 key 操作同时落到同一个节点上，可以在 key 后面加上{hash tag}。

   

9. **Redis 分布式锁实现**

   通过 `setnx key val ex seconds` 来实现分布式锁。

   nx 确保了只有一个线程获取到锁，防止有线程获取到锁后被其他线程替换。

   ex 过期时间，确保即使没有手动释放锁成功也会到时间自动释放锁。防止死锁。

   key 为锁的标识。

   val 一般为获取锁的线程，可以实现重入锁（增加一个重入次数即可）。



# 操作系统

1. **BIO**

   传统一个线程对应一个请求，请求处理完后，线程才能处理其他请求。

   然后采用

2. **NIO**



# 分布式

1. ## Raft 算法

   Raft 算法是 Paxos 算法的一种简化实现。

   > Redis 中哨兵集群中的哨兵 Leader 选举和 Redis-Cluster 中的 Master 节点选举都是基于Raft算法实现的。

   http://thesecretlivesofdata.com/raft/

   ### 角色

   Raft 算法中有三种角色：

   * Leader 领导者：负责系统所有修改操作，并将这些结果（数据）同步到各个 Follower 节点（一般通过日志）。
   * Candidate 候选者：Leader 的候选人。如果系统没有 Leader，则会从 Candidate 中选出一个当选 Leader。
   * Follower 追随者：所有节点一开始都是 Follower，如果没有收到 Leader 消息，则会变成 Candidate 参与 Leader 竞选；当有 Leader 竞选出来后，Follower 则负责接收 Leader 发送的日志，进行数据同步。

   

   ### Raft 算法流程

   Raft 算法流程实际上分为两种：

   #### Leader 选举

   Leader 角色实际上是拜占庭将军问题的主将军解决方案实现，通过 Leader 作为系统的决策者，从而避免多个决策者导致数据不一致的问题。

   Leader 选举分为两种情况：

   **情况一：初始选举**

   1. 集群中所有节点一开始都是 Follower 角色。
   2. 每个节点都会随机生成一个 timeout 时间（150ms~300ms），可以看做是一个定时器。当节点一定时间内没有收到 Leader 发送的心跳包，并且 timeout 时间到期，则此时节点会成为 Candidate，并向其他节点发起 Leader 选举请求，该请求中会附带票据，票据内容为节点选择自己作为 Leader 节点。
   3. 其他节点收到选举请求后，会将收到的票据内容作为自己的票据内容进行投票，并返回响应给发起者。
   4. 如果发起者收到半数以上的投票，则该节点为新的 Leader 节点。

   

   > 选举出来的 Leader 节点会对其他 Follower 节点发送心跳包，Follower 节点收到心跳包后会将 timeout 时间清零，重新倒计时，从而避免 Leader 存在情况下，重新发起 Leader 选举节点的问题。因此需要确保 timeout 时间一定比心跳包间隔长。

   

   上述过程中存在两个问题：

   **周期（Term）问题：**

   由于网络原因（如丢失、延迟、重试等），节点可能收到多个选举请求并作出投票。那么此时发起选举的节点可能收到来自同一个节点的多个投票。而这多个投票实际只有发起选举者最新一次发起对应的投票才有效，而其他票应该标识为无用的票。

   对于该问题的解决方案：

   1. 每个节点会持有一个标识：周期（Term）。
   2. 当节点发起选举请求时，会对递增周期，并在选举请求中自己的投票附上递增后周期。
   3. 节点收到选举请求时，会有两种情况：
      * 如果请求中的票据所在的周期比自身记录周期小，则表示该票据是来自旧的选举请求，即无用请求，应该丢弃。
      * 如果请求中的票据所在的周期比自身记录周期大，则更新自身记录的周期为票据的周期，并将票据的内容作为自己的票据内容进行投票响应回请求发起者。

   

   **多 Candidate 问题：**

   假设刚好有两个 Follower 的 timeout 到期，则这两个节点会同时变成 Candidate 并发起选举请求（各自都投自己为 Leader）。如果集群节点数为偶数，则此时可能存在结果为两个 Candidate 各获得一半的投票数，因此需要重新发起新的一轮投票。

   为了避免无限循环结果：两个 Candidate 各获得一半的投票数，又重新发起新的一轮投票。

   因此对于 timeout 时间应该设置为随机数，从而避免同一时间多个节点 timeout 时间相同，同时发起选举请求。

   > 虽然 timeout 时间设置随机数，但还是存在刚好相同的可能性，因此建议集群节点为奇数，则确保至少有一个 Candidate 获取到的投票数过半。

   

   **情况二：Leader 故障重新选举**

   由于 Leader 可能存在宕机或网络故障导致不可用，因此需要一种机制重新选举出新的 Leader 节点。

   1. 如果某个 Follower 节点 timeout 到期了（由于没有收到 Leader 发来心跳包），此时判定 Leader 不可用，重新发起选举请求，逻辑和上述一致。
   2. 挂掉的 Leader 重启后，收到新的 Leader 发起的心跳包，发现周期不一致，则表明已经进行了新的一轮选举，此时会更新周期，并将自己转成 Follower 节点。

   

   #### 复制日志

   复制日志实际是数据同步的一个过程：

   1. Leader 节点会接受客户端的事务（修改）操作，并将数据结果记录在本地日志（数据处于 uncommitted 状态）。
   2. Leader 节点会在下一次发送心跳包的时候附带上提案（提案内容为该数据）。
   3. Follower 节点收到心跳包中的提案后，会将数据记录在本地日志中（数据处于 uncommitted 状态），然后发送响应给 Leader。
   4. Leader 节点如果收到过半的节点的响应（包括自身），则会将本地日志的该数据修改为 commit 状态（表示数据已提交），然后返回响应给客户端。
   5. Leader 节点会发送 AppendEntries 请求给 Follower 节点。
   6. Follower 节点收到 AppendEntries 请求后，会将本地日志对应的数据修改为 commit 状态。

   

   **网络分割问题**

   由于网络异常，可能会导致集群中出现网络分割，即集群中的部分节点之间不能互相通信。

   如集群中5个节点本来可以互相通信，但由于网络异常，导致节点1-3可以互相通信，节点4-5可以互相通信，从而出现网络分割成两个集群。

   <img src="C:\Users\63190\Desktop\pics\Raft网络分割1.jpg" alt="Raft网络分割1" style="zoom:67%;" />

   由于网络分割导致两个新的小集群，此时每个小集群会各自重新选出一个新的 Leader。

   <img src="C:\Users\63190\Desktop\pics\Raft网络分割2.jpg" alt="Raft网络分割2" style="zoom:67%;" />

   此时两个小集群会存在一个多数派集群（节点数量为原先的半数以上），另一个则为少数派集群（节点数量为原先的半数以下）。

   此时少数派集群的 Leader 无论发起什么提案，数据都只会被记录在本地日志（处于 uncommitted 状态），而不会被 commit（应为 Leader 节点收不到过半的响应），而多数派集群则会正常复制日志。

   当网络恢复时，所有节点可以互相通信，此时集群处于数据不一致状态（原少数派集群的节点会有 uncommitted 数据，原多数派集群会有 commit 数据）。Raft 算法会进行数据恢复：

   1. 少数派集群的 Leader 会退回 Follower 状态，并告诉客户端请求操作失败（因为 uncommitted 数据不会被 commit）。
   2. 原多数派集群的 Leader 依旧为 Leader，原少数派集群的节点收到 AppendEntries 请求后，会对 uncommitted 数据进行删除，并同步原多数派集群中新增的 commit 数据。

   

   ## ZAB 协议

   ZAB 协议全称：Zookeeper Atomic Broadcast（Zookeeper 原子广播协议）。

   ZAB 协议是为分布式协调服务 Zookeeper 专门设计的一种支持 **崩溃恢复** 的 **原子广播** 协议。

   基于该协议，Zookeeper 实现了一种 **主备模式** 的系统架构来保持集群中各个副本之间数据一致性。

   

   ### 角色

   ZAB 中将节点分为三种角色：

   * Leader 领导者：负责接收处理客户端的所有操作，如果是事务（修改）操作则会将对应结果（数据）封装成事务提议（Proposal）原子广播给所有 Follower 节点，从而实现数据同步，即数据一致性。
   * Follower 追随者：负责接收处理客户端的读操作（如果是事务请求会转发给 Leader 执行）。对于 Leader 发送的事务提议（Proposal）进行同步，并参与 Leader 选举投票。
   * Observer 观察者：和 Follower 唯一不同的是不参与 Leader 选举投票。

   

   ### 名词解释

   * myid：服务器ID，每个服务器都有一个唯一的id。

   * zxid：事务id 也叫当前服务器中最新的数据ID。Zxid 是一个 64位的数字，其高 32 位是 epoch（如果有新的 Leader ，那么该 epoch 会自增），低32位用来递增计数（每增加一个事务提议 Proposal，即数据发生变更同步，则会递增生成一个新的 Zxid）。

     每当选举产生一个新的 Leader ，就会从这个 Leader 服务器上取出本地事务日志充最大编号 Proposal 的 zxid，并从 zxid 中解析得到对应的 epoch 编号，然后再对其加1，并将低32位数字归零，从而生成一个全新的 zxid。

   * 投票 epoch：选举投票轮次。同一轮投票过程中的 epoch 值是相同的，每投完一次票这个数据就会增加。用于与接收到的投票信息中的 epoch 比较，根据不同的值做出不同的判断。

   > Zxid 中的 epoch 和投票 epoch 不一样：
   >
   > * 前者是用于区分是否发生了 Leader 变更，如果节点收到的 Proposal 中的 Zxid 是旧的 epoch（判断高 32 位），则会丢弃消息。
   > * 后者是用于选举过程中，标记当前投票处于那一轮，如果是旧的 epoch 轮次投票，则应该忽略掉。

   ### 流程

   #### 初始选举

   每个节点启动时节点状态都为 looking（竞选状态）。如果集群只有一个节点，则不会开始选举，当集群多于一个节点，就会开始进行 Leader 选举。

   1. 更新 epoch，标识发起新的一轮选举。

   2. 每个节点都会持有自己投票（一开始都会投票给自己），投票内容为（myid、zxid、投票 epoch），然后将自己的投票广播给集群中其他节点。

   3. looking 状态的节点会不断接收其他节点发送的投票，并对接收到的投票进行一下判断：

      1. 对于 looking 状态的投票：

         1. 如果投票的 epoch 比自身的 epoch 大。说明自身节点的投票轮次是旧的，因此需要更新自身的 epoch，同时清空 recvset。然后将该投票跟自己持有的投票进行比较，看是否需要更新自己的投票，比较规则如下：

            1. 比较 zxid。 zxid 越大越优先，表示节点数据越新；
            2. 其次比较 myid，myid 大者优先。

            如果收到的投票优于自身持有的投票，则会将收到的投票作为自身投票，然后广播给其他节点。

         2. 如果投票的 epoch 比自身的 epoch 小。说明对方节点处于旧的 epoch，忽略该投票。

         3. 如果投票的 epoch 等于自身的 epoch。说明两个节点处于同一轮投票中，和上述一样将该投票和自身投票进行比较，如果收到的投票优于自身持有的投票，则会将收到的投票作为自身投票，然后广播给其他节点。

         4. 对于 epoch 大于或者等于的情况，都意味着收到的投票是有意义的，因此会将其存放在 receset 集合中，用于后续统计票数使用。

      > 如果开始竞选后，有新的节点加入集群，一般情况下该新节点处于旧的 epoch，其发起的投票就会触发上面的第二种情况（投票的 epoch 比自身的 epoch 小），其收到的投票就会触发第一种情况（投票的 epoch 比自身的 epoch 大）。最终集群节点都会同步在一个新的 epoch 轮次中进行投票，即第三种情况（投票的 epoch 等于自身的 epoch）。

   4. 对收到的投票处理完后，会判断是不是已经收集到了本轮 epoch 所有节点的投票：

      1. 如果收集完，则会根据投票结果判断是否有过半的节点投票自己作为 Leader，如果有则设置自己的角色为 Leader，反之则为 Follower，最后退出选举过程。
      2. 如果没有收集完，则可以判断已有投票中是否有节点获得了过半的支持成为 Leader，如果有则尝试在200ms 内接收投票（防止有新的节点加入，导致投票结果变更），如果没有新的投票，则表明集群中的节点认可了该投票结果，同样也设置角色并退出选举过程。

   ![image-20211028174328316](C:\Users\63190\AppData\Roaming\Typora\typora-user-images\image-20211028174328316.png)

   #### 数据同步（原子广播）

   原子广播实际上为消息广播，是一种类 2PC 协议。

   Leader 负责将一个客户端的事务请求转换为一个事务提议（Proposal），并将该 Proposal 分发给集群中的所有Follower。之后等待所有Follower的反馈，一旦超过半数的 Follower 进行了正确的反馈，那么Leader会再次向所有 Follower 发起 Commit 消息，要求将上一次 Proposal 进行提交。

   具体流程如下：

   1. 客户端发起一个事务（修改）请求，如果是 Follower 节点接收到则会转发给 Leader 节点。

   2. Leader 接收到消息请求后会将其转换成事务提议（Proposal），并为该 Proposal 生成一个全局唯一的 64位 自增 ID，叫 Zxid。（Zxid 越大意味着数据越新）
   3. Leader 为每个 Follower 准备了一个 FIFO 队列（通过 TCP 协议来实现，以实现了全局有序这一个特点）将需要广播的 Proposal 依次放到队列中取，并且根据 FIFO 策略进行消息发送。
   4. 当 Follower 节点接收到 proposal，会首先将其以事务日志的方式写入本地磁盘中，写入成功后向 Leader 反馈一个 Ack 响应消息。
   5. 当 Leader 接收到半数以上 Follower 的 Ack 响应消息后，即认为消息发送成功，Leader 就会向所有的 Follower 节点广播 commit 消息，然后自身会在本地完成事务提交。
   6. 当 Follower 收到 commit 消息以后，会将对应的 Proposal 提交。

   

   **ZAB 协议和 2pc 区别：**

   ZAB 协议和 2pc 事务不一样的地方在于，ZAB 协议不能终止事务， Follower 节点要么 ACK 给 Leader ，要么抛弃 Leader ，因此 Leader 只需要收到过半数的节点响应，即可认为可以提交 Proposal（2pc 则需要阻塞等待收到所有节点的响应才能作出提交/回滚决策）。该做法虽然会导致某一个时刻 Follower 节点和 Leader 节点的数据不一致，但最终所有节点都会处于数据一致性。以为避免了 2pc 的阻塞等待问题，因此提升了集群的整体性能。

   

   **通信方式：**

   客户端与节点之间的通信采用 NIO 的方式。

   Leader 和 Follower 节点之间的通信采用 TCP 方式。Leader 为每个 Follower 维护一个消息队列，从而实现异步解耦。

   

   #### 崩溃恢复

   **崩溃导致的问题**

   （一）不能处理事务请求

   ZAB 协议通过 Leader 节点处理事务操作，并通过原子广播将事务消息发送到 Follower 节点，从而实现数据同步，因此 ZAB 协议正常运作基于 Leader 节点可用的情况。

   当运行期间 Leader 不可用，此时没有 Leader 节点接收处理客户端的事务请求，即处于崩溃状态。

   > 对于该问题，需要在 Leader 崩溃时，重新从 Follower 节点中选出新的 Leader 节点，从而保证服务可用。

   （二）数据不一致

   1. 当 Leader 收到过半 Follower 节点对 Proposal 的 ack 响应时，此时 Leader 节点会发送 commit 消息给所有 Follower 节点，并提高本地的 Proposal。如果在 Leader 发送 commit 消息给所有 Follower 节点的途中崩溃不可用，那么可能会导致部分 Follower 节点 commit 了该 Proposal，部分没有 commit 该 Proposal，即节点之间产生数据不一致的情况。

   > 对于该问题，需要选出 Zxid 最大的 Follower 节点作为新的 Leader（确保新的 Leader 拥有最新的数据，即新的 Leader 保证 commit 了旧的 Leader 发起 commit 消息的 Proposal），新的 Leader 会将所有 commit 过的 Proposal 同步给所有的 Follower 节点。

   2. 当 Leader 原子广播了 Proposal 消息后，还未收到过半 Follower 节点的 ack 响应就崩溃，导致 uncommitted 的 Proposal 可能存在 Follower 节点中。

   > 对于该问题，新的 Leader 的 Zxid 高 32 位代表的 epoch 自增，从而使得 Follower 节点收到新的 Leader 的 Zxid 后，分析获得最新的 epoch，并将自身旧的（epoch 比最新的 epoch小）未提交的 Proposal 删掉。

   

   因此 Leader 节点会和 Follower 节点进行数据同步，当超过半数的节点完成数据同步后，ZAB 协议就会退出恢复模式。

   崩溃恢复具体流程如下：

   **运行期间 Leader 选举**

   流程如下：

   1. 当 Leader 崩溃或者 Leader 失去过半的 Follower 节点联系，这时会进入崩溃恢复模式，所有非 Observer  节点服务器状态变为 **looking（竞选状态）**。

   2. 更新 epoch，标识发起新的一轮选举。

   3. 每个节点都会持有自己投票（一开始都会投票给自己），投票内容为（myid、zxid、投票 epoch），然后将自己的投票广播给集群中其他节点。

   4. looking 状态的节点会不断接收其他节点发送的投票，并对接收到的投票进行一下判断：

      1. 对于 looking 状态的投票：

         1. 如果投票的 epoch 比自身的 epoch 大。说明自身节点的投票轮次是旧的，因此需要更新自身的 epoch，同时清空 recvset。然后将该投票跟自己持有的投票进行比较，看是否需要更新自己的投票，比较规则如下：

            1. 比较 zxid。 zxid 越大越优先，表示节点数据越新；
            2. 其次比较 myid，myid 大者优先。

            如果收到的投票优于自身持有的投票，则会将收到的投票作为自身投票，然后广播给其他节点。

         2. 如果投票的 epoch 比自身的 epoch 小。说明对方节点处于旧的 epoch，忽略该投票。

         3. 如果投票的 epoch 等于自身的 epoch。说明两个节点处于同一轮投票中，和上述一样将该投票和自身投票进行比较，如果收到的投票优于自身持有的投票，则会将收到的投票作为自身投票，然后广播给其他节点。

         4. 对于 epoch 大于或者等于的情况，都意味着收到的投票是有意义的，因此会将其存放在 receset 集合中，用于后续统计票数使用。

         > 如果开始竞选后，有新的节点加入集群，一般情况下该新节点处于旧的 epoch，其发起的投票就会触发上面的第二种情况（投票的 epoch 比自身的 epoch 小），其收到的投票就会触发第一种情况（投票的 epoch 比自身的 epoch 大）。最终集群节点都会同步在一个新的 epoch 轮次中进行投票，即第三种情况（投票的 epoch 等于自身的 epoch）。

      2. 对于 leading/following 状态的投票：

         1. 如果投票的 epoch 等于自身的 epoch，将该数据保存到 recvset。如果是 Leading 状态，则表明已经有节点获得投票结果，并且该节点票选其自身为 Leader。因此需要校验本节点收集的投票是否有半数以上的节点选举它，如果校验通过，则将自己选举状态改为 following 并退出选举过程。
         2. 如果投票的 epoch 不等于自身的 epoch，此时情况可能是集群节点已经获得投票结果（选定 Leader 节点），但本节点为新加入节点，实际上可能会影响已经获得的投票结果，因此需要将投票保存到 outofelection 中，再根据 outofelection 来判断本节点收集的投票是否有半数以上的节点选举出来的 Leader 与投票中选定的 Leader 是否一致，如果一致，则更新 epoch，并设置选举状态、退出选举过程。

   5. 对收到的投票处理完后，会判断是不是已经收集到了本轮 epoch 所有节点的投票：

      1. 如果收集完，则会根据投票结果判断是否有过半的节点投票自己作为 Leader，如果有则设置自己的角色为 Leader，反之则为 Follower，最后退出选举过程。
      2. 如果没有收集完，则可以判断已有投票中是否有节点获得了过半的支持成为 Leader，如果有则尝试在200ms 内接收投票（防止有新的节点加入，导致投票结果变更），如果没有新的投票，则表明集群中的节点认可了该投票结果，同样也设置角色并退出选举过程。

   

    **数据恢复**

   1. 完成 Leader 选举后（新的 Leader 具有最高的zxid），会将自身的本地事务日志中的所有 Proposal 和所有 Follower 节点中的所有 Proposal 进行对比。对比过程中会进行以下数据恢复：
      1. 确保 Follower 节点对 Leader 节点已经提交过的 Proposal 进行提交。
      2. 对于节点在上一个 epoch 中未被 commit 的 Proposal 进行回滚。
   2. 进行完上述的数据恢复后，Leader 才会把该 Follower 加入到真正可用的 Follower 列表中，当有过半的 Follower 节点完成数据恢复（数据和 Leader 保持一致），则 Leader 可以开始工作（接收事务请求，然后提出新的 Proposal）。
   3. 当新的节点加入到集群中时，节点会直接进入数据恢复模式，和 Leader 节点进行数据同步。同步完成后即可正常对外提供非事务请求的处理。



# 项目



## 自我介绍

面试官，下午好。我叫李嘉伟。关于我的工作经历，我在2018年11月成为三七互娱的实习生，并在接下来两年多的时间在三七互娱担任游戏开发。在三七工作期间参与了三款游戏的开发，其中两款已经上线并取得单月流水过亿的成绩。第一款游戏是一款 H5 页游，在这款游戏开发过程中，我主要是作为实习生负责处理日常 bug 修复以及熟悉游戏开发的架构。第二款游戏是末日沙城，是一款手游，在这款游戏中我参与了上线前的开发即测试以及上线后的迭代维护整个过程。第三款游戏是基于第二款游戏的框架，并总结一些开发中遇到的问题，对游戏技术架构往分布式架构进行升级。详细情况可以在我的简历中了解。希望可以通过接下来的面试交流过程中，能让面试官更加了解到我。



## 匹配服

**（一）为什么有匹配服？**

在末日沙城中，每个服都是一个单体应用，因为一个服的人数会不断减少，因此提出了新的需求：多个服为一组，共同参与玩法或者活动。

**（二）主从服设计**

由于多个服共同参与，意味着服与服之间需要通信来进行数据交互。

为了维护数据一致性的问题，采用了主从服的设计。

主服主要负责事务性操作，从服只负责读操作。

数据存储在主服，并且会有同步机制同步回从服。

从服收到客户端的事务性操作会转发给主服，由主服来响应客户端。因此客户端除了对本服以外还要对主服建立连接。

**（三）分组及主从确定**

1. 所有服启动时都会发送自己的信息给匹配服，并定时发送心跳包维持链接状态。
2. 匹配服会定时对持有的所有服，按照玩法对应的规则进行分组，并从每个组内选举一个主服，并把分组信息推送给组内所有服。
3. 服务器会定时推送信息给匹配服，也会定时的去拉取匹配信息并缓存到。



**（四）故障转移**

1. 当匹配组的主服挂掉，则匹配服会对应在组内重新选出新的主服，数据同步越高越优先（数据同步高地可以使用 epoch 表示）。



**（五）匹配服集群**

游戏服跨服玩法一定要在匹配服可用的情况下才能进行，原因是要确保匹配信息是最新的。因此为了防止匹配服单点故障导致跨服玩法不可用，对匹配服进行集群，从而实现匹配服高可用。

集群意味着需要一个 Master 节点进行事务型操作，那么需要一种机制去实现 Master 选举：

第一个版本：

匹配服根据类似于 redis 哨兵的 paxos 一致性算法从集群中选举出 master 节点提供匹配服服务。

第二个版本：

基于第三方分布式协调组件（采用 Zookeeper）方式实现 Master 选举。简单来说就是创建临时有序节点，节点序号最小的即为 Master 节点。



**（六）优化**

由于后面服务进行拆分部署（微服务），那么意味着游戏组的主从服可以去掉。

1. 数据的操作、存储不再是落到游戏服上，而是在落到具体的服务应用进行处理，数据也会落到对应的服务的数据库中存储。
2. 不需要进行数据同步，而是通过调用服务接口访问数据，热点数据可以缓存到 Redis。

微服务带来的问题：

1. 多个服并发访问某个服务应用，可能会导致数据不一致，因此需要进行同步操作，如分布式锁。



## 服务拆分

服务拆分好处：

1. 

## 活动

对于常见的活动，如购买限购礼包，可能涉及以下步骤：

1. 防止重复请求
2. 库存减少
3. 创建订单
4. 支付
5. 发奖
6. 积分赠送
7. 排行榜



在单应用下，所有的操作都在同一个数据库中，因此可以采用本地事务的形式，确保数据一致性。

（一）服务拆分

将上述操作按照业务性进行拆分，

### 购买礼包

购买礼包其流程一般如下：

#### 防止重复请求

为了解决重复收到多次请求（可能网络原因，可能客户端发了多次）。

* 前端可以按钮置灰
* 后端采用锁的方式

通过锁的方式确保了只会有一个请求进行操作，当购买礼包执行完（成功或者失败）就会释放锁。

**本地锁实现：**

key为用户id+商品id+商品数量，val为线程

通过 putIfAbsent 放到 ConcurrentHashMap（确保只有一个线程获取成功）。

**优良版：Redis 实现**

单体应用中，我们可以控制锁的释放。但在分布式架构中，由于购买礼包的多个流程可能分布在不同的系统中，控制本地锁的释放十分繁杂，因此采用分布式锁的方案，引入 Redis 第三方组件。

通过 Redis 本身单线程的特点，确保了只有一个线程获取到锁。

通过 sexnx 保证只有一个线程获取到锁，ex 保证锁最终一定能被释放成功。

#### 库存减少

库存减少可以看作两个步骤：**判断库存是否够**+**更新数据库值**，此时会遇到两种问题：

1. 多用户同时购买同一个礼包（多线程），可能会导致超卖（因为先判断再去更新）。

   第一种解决方案为：加锁的方式（本地或者 Redis实现），确保只有一个线程执行，效率低。

   第二种解决方案为：乐观锁，update。

   ```sql
   update Goods set count = count - #{购买数量} where id = #{id} and count - #{购买数量} >= 0;
   ```

2. 每次判断库存是否够都需要查询数据库，效率低。

   解决方案：引入缓存。首先判断是否缓存了库存值，如果没有则从数据库获取被更新缓存值。先扣除缓存值，再更新数据库。

   * 可以通过本地使用 Atomic 缓存库存值，先减少缓存值，再乐观锁 update 库存值。
   * 也可以使用 Redis 缓存库存值，redis 可以提供对 key 设置过期时间，从而避免大量缓存商品库存值。首先获取库存缓存值，判断是否够，如果够则使用 incre 方式减少库存，并判断 incre 返回值是否大于等于0，不是则意味着超卖，需要恢复缓存值。（这里实际上可以采用 lua 脚本，将判断和incre操作放在 lua 脚本中，从而确保整个操作原子性，不会出现缓存超卖的情况）

**订单**

库存减少成功后，此时就要生成订单（实际上为插入一条订单数据）。

因为是单体应用，此时可以将库存减少和生成订单放在同一个事务中，如果事务执行失败，则需要回滚库存缓存值。

对于分布式架构中，库存逻辑和订单逻辑可能处于不同系统、不同的数据库，因此我们可以才用基于 2pc 的分布式事务。但一般都是采用最终一致性的柔性事务。

在更新数据库库存时，同时记录交互记录：库存处理状态为已处理，订单处理状态为未处理。

通过线程不断轮询交互记录，将消息发布到 mq 中，发布成功后就可以删除记录，

订单系统去获取 mq 中对应的消息，然后进行订单创建，如果失败则重试，重试一定次数后可以发布失败消息表，可以对失败消息表采取重试或者回退库存或者人工干预。

#### 支付

支付分为两种：外部支付 sdk 或者扣除点券。

扣除点券方式：实际上修改数据库，因此可以将其加入到上面的本地事务中，同样如果失败则需要对回退库存缓存。

外部支付 sdk：这种实际上是调用远程接口，因此一般会等待一定的时间，如果超时没有支付成功，那么需要将库存和订单进行回退，并且回退库存缓存。

上述这些操作我们说要么全部执行成功，要不全部回退。而对于发奖、积分赠送这些操作来说，如果上述操作都执行成功，那必然会执行并且这些操作不会影响主体业务流程，只要求最终一致性。因此采用了消息队列的方式，将订单支付成功的消息发布到对应的本地消息队列，由对应的线程去获取消息进行相关处理。

#### 发奖

获取消息，并进行发奖（入库操作）

#### 积分赠送

获取消息，并进行增加积分。



## 排行榜

积分可能会用于排行榜：

1. 由于一开始排行榜只对本服玩家进行，因此设计成本服实现。

   需求：某个副本的通关排行榜

   数据：持久化记录，id为玩家id，记录玩家通过关卡、时间、耗时等信息。

   数据结构：LinkedList（存储排行榜数据）+Map（存储排名）

   操作：

   1. 初始化。加载所有记录到list，并进行排序；将 list 的排名缓存到 map 中（key 玩家id，val 排名）。
   2. 查询。查询玩家排名直接从 map 中获取，查询排行榜信息从 list 获取。
   3. 插入。插入新的记录到 list 中，并进行重排序，更新排名 map。
   4. 更新。根据玩家id找到对应的排名（索引），根据更新list中对应的索引的值，并进行重排序，重排序后更新排名。

2. 性能问题：由于排行榜不需要实时，而且一个服的玩家有限，因此采取消息队列的方式，将排行榜更新操作放到队列中，

3. 由于后续出现排行榜对多个服的玩家进行排名，基于本地的实现复杂，因此独立抽出排行榜服务。

   1. 并且使用redis 的 sort set结构实现排行榜



## 测试



1. cpu 使用率过高。
   1. 首先查看是什么进程的那个线程使用频繁。可以通过top命令和jstack查看线程。
   2. 用户请求线程：qps过高，可以考虑集群的方式减少单点qps。
   3. 业务线程：如一些轮询的业务（空转），可以考虑改成定时。业务执行时间长，可以考虑异步执行如消息队列。
   4. gc频繁：dump堆内存快照，通过 mat工具分析判断当前内存对象是否合理，如内存泄露。或者是使用其他的垃圾回收器。增加内存大小。
2. 死锁，通过jstack判断是否出现死锁，从业务逻辑上避免死锁出现。
3. 测试主体业务流程响应时间，可以考虑缓存或者异步的方式。

![JVM 调优指南](C:\Users\63190\Desktop\pics\JVM 调优指南.jpg)



9. 帧同步和状态同步的区别

   游戏中，多个客户端需要看到相同的信息（如技能、动作之类的）。

   帧同步和状态同步的区别在于战斗逻辑写在哪里。

   帧同步的战斗逻辑由客户端处理。客户端的逻辑请求都会发送给服务端，服务端把这一时间段的操作同步给客户端，有客户端根据这一帧发生的事情进行处理，并在客户端展现出来。

   状态同步的战斗逻辑由服务端处理。由于客户端并不能知道游戏所有的信息，因此不能进行战斗逻辑处理，只有服务端才有所有信息，因此需要客户端将操作发送给服务端，服务端处理完后，将结果返回给客户端，客户端展示结果。
